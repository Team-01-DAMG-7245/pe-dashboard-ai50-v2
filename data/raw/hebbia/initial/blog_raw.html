<!DOCTYPE html><html lang="en" class="__variable_490f46 font-sans text-primary bg-white"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/1b228b4a0c384dad-s.p.woff" as="font" crossorigin="" type="font/woff"/><link rel="preload" href="/_next/static/media/77230bf07519a880-s.p.woff" as="font" crossorigin="" type="font/woff"/><link rel="preload" href="/_next/static/media/e4e2fb3a0f27f527-s.p.woff" as="font" crossorigin="" type="font/woff"/><link rel="stylesheet" href="/_next/static/css/ecd420d635265f57.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-41f05cabd64f3f4d.js"/><script src="/_next/static/chunks/fd9d1056-00a8103e67273b5c.js" async=""></script><script src="/_next/static/chunks/117-2b33888a05f9bff9.js" async=""></script><script src="/_next/static/chunks/main-app-2dcde4753ea0d175.js" async=""></script><script src="/_next/static/chunks/45-fd881c86cc40ada7.js" async=""></script><script src="/_next/static/chunks/699-646e730b035611b4.js" async=""></script><script src="/_next/static/chunks/app/blog/error-77f9f1c60163c1f3.js" async=""></script><script src="/_next/static/chunks/320-9ffc19bff26ffb6d.js" async=""></script><script src="/_next/static/chunks/app/layout-8c37041e3ac03a0c.js" async=""></script><script src="/_next/static/chunks/878-9f3534a968d14183.js" async=""></script><script src="/_next/static/chunks/app/not-found-fc6c331b82e3041a.js" async=""></script><script src="/_next/static/chunks/106-679e3fb3e86e138a.js" async=""></script><script src="/_next/static/chunks/app/blog/page-de45143c3e909f5e.js" async=""></script><link rel="preload" href="https://client-registry.mutinycdn.com/personalize/client/b59bc51867969ec5.js" as="script"/><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-NMD54N7Z" as="script"/><link rel="preload" href="https://cmp.osano.com/169xbBUKm9qUnAu6o/efc596b5-cfb1-40eb-b39b-4212f85a9954/osano.js" as="script"/><title>Blog</title><meta name="description" content="AI for Finance."/><link rel="manifest" href="/manifest.webmanifest" crossorigin="use-credentials"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="32x32"/><link rel="icon" href="/icon.svg?104043f64f056642" type="image/svg+xml" sizes="any"/><link rel="apple-touch-icon" href="/apple-icon.png?1a5fcb960187c387" type="image/png" sizes="180x180"/><meta name="next-size-adjust"/><script>(self.__next_s=self.__next_s||[]).push([0,{"children":"(function(){var a=window.mutiny=window.mutiny||{};if(!window.mutiny.client){a.client={_queue:{}};var b=[\"identify\",\"trackConversion\"];var c=[].concat(b,[\"defaultOptOut\",\"optOut\",\"optIn\"]);var d=function factory(c){return function(){for(var d=arguments.length,e=new Array(d),f=0;f<d;f++){e[f]=arguments[f]}a.client._queue[c]=a.client._queue[c]||[];if(b.includes(c)){return new Promise(function(b,d){a.client._queue[c].push({args:e,resolve:b,reject:d})})}else{a.client._queue[c].push({args:e})}}};c.forEach(function(b){a.client[b]=d(b)})}})();","id":"mutiny-shim"}])</script><script>(self.__next_s=self.__next_s||[]).push(["https://client-registry.mutinycdn.com/personalize/client/b59bc51867969ec5.js",{"data-cfasync":"false","id":"mutiny-client"}])</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased cursor-default"><main><header class="top-0 relative"><nav data-nav-color="primary" class="fixed lg:hidden top-[0px] w-full z-20"><div class="flex w-full h-mobile-nav border-steel border-b"><div class="w-[11px] lg:w-rail border-r border-steel flex-shrink-0 flex-grow-0 h-full bg-marble"></div><div class="flex-grow h-full bg-marble flex items-center"><div class="flex flex-row items-center px-sm justify-between flex-grow"><a href="/"><svg width="93" height="16" viewBox="0 0 93 16" version="1.1" xmlns="http://www.w3.org/2000/svg"><title>Hebbia</title><path d="M25.9426571,0.00249941429 L25.9426571,6.40974286 L33.7397143,6.40974286 L33.7397143,0.00249941429 L36.6077143,0.00249941429 L36.6077143,15.6863143 L33.7397143,15.6863143 L33.7397143,9.23408571 L25.9426571,9.23408571 L25.9426571,15.6863143 L23.0746,15.6863143 L23.0746,0.00249941429 L25.9426571,0.00249941429 Z M41.4914286,12.8744857 C42.0288571,13.4043714 42.7688571,13.6692857 43.7097143,13.6692857 C44.4271429,13.6692857 45.0245714,13.5280857 45.5017143,13.2431429 C45.9791429,12.9594571 46.3228571,12.5483143 46.5328571,12.0109429 L49.4234286,12.0109429 C49.1248571,13.1906571 48.4637143,14.1504286 47.44,14.8902571 C46.4165714,15.6300857 45.1657143,15.9987429 43.6871429,15.9987429 C42.4925714,15.9987429 41.4391429,15.7300571 40.528,15.1926857 C39.6168571,14.6553143 38.9145714,13.8967429 38.4222857,12.9182286 C37.93,11.9397143 37.6822857,10.8087143 37.6822857,9.52402857 C37.6822857,8.23931429 37.9285714,7.10834286 38.4222857,6.1298 C38.9145714,5.15128571 39.6131429,4.39397143 40.5168571,3.85534286 C41.4202857,3.31797143 42.4625714,3.04928571 43.6422857,3.04928571 C44.822,3.04928571 45.8642857,3.31797143 46.7677143,3.85534286 C47.6714286,4.39271429 48.37,5.15128571 48.8622857,6.1298 C49.3545714,7.10834286 49.602,8.23931429 49.602,9.52402857 C49.602,9.89768571 49.5797143,10.2563429 49.5345714,10.6000286 L40.4831429,10.6000286 C40.618,11.5860286 40.9542857,12.3446 41.4914286,12.8744857 Z M46.824,8.26931429 C46.5102857,6.34225714 45.4494286,5.37874286 43.6422857,5.37874286 C42.7611429,5.37874286 42.0588571,5.63242857 41.5365714,6.14105714 C41.0128571,6.64842857 40.6705714,7.35828571 40.5054286,8.26931429 L46.824,8.26931429 Z M53.4548571,0.00249941429 L53.4548571,4.259 C54.4108571,3.45294286 55.5982857,3.04928571 57.018,3.04928571 C58.1377143,3.04928571 59.1237143,3.31422857 59.976,3.84408571 C60.8271429,4.37397143 61.488,5.1288 61.9591429,6.10731429 C62.4302857,7.08582857 62.6654286,8.22431429 62.6654286,9.52402857 C62.6654286,10.8237143 62.4302857,11.9622 61.9591429,12.9407143 C61.4894286,13.9192286 60.8282857,14.6740571 59.976,15.2039429 C59.1237143,15.7338 58.1388571,15.9987429 57.018,15.9987429 C55.5094286,15.9987429 54.2697143,15.5501143 53.2988571,14.6540571 L53.2988571,15.6850857 L50.6768571,15.6850857 L50.6768571,0.00249941429 L53.4548571,0.00249941429 Z M58.9337143,12.5270571 C59.5085714,11.7959714 59.796,10.7949714 59.796,9.52525714 C59.796,8.25557143 59.5085714,7.25454286 58.9337143,6.52345714 C58.3588571,5.7924 57.5702857,5.42622857 56.5705714,5.42622857 C55.5708571,5.42622857 54.7782857,5.7924 54.196,6.52345714 C53.6137143,7.2558 53.3225714,8.25682857 53.3225714,9.52525714 C53.3225714,10.7937143 53.6137143,11.7959714 54.196,12.5270571 C54.7782857,13.2594 55.5708571,13.6243143 56.5705714,13.6243143 C57.5702857,13.6243143 58.3588571,13.2581429 58.9337143,12.5270571 Z M66.5182857,0.00249941429 L66.5182857,4.259 C67.4742857,3.45294286 68.6614286,3.04928571 70.0797143,3.04928571 C71.1994286,3.04928571 72.1857143,3.31422857 73.038,3.84408571 C73.8888571,4.37397143 74.55,5.1288 75.0211429,6.10731429 C75.4911429,7.08582857 75.7271429,8.22431429 75.7271429,9.52402857 C75.7271429,10.8237143 75.4922857,11.9622 75.0211429,12.9407143 C74.55,13.9192286 73.8888571,14.6740571 73.038,15.2039429 C72.1868571,15.7338 71.2008571,15.9987429 70.0797143,15.9987429 C68.5714286,15.9987429 67.3317143,15.5501143 66.3605714,14.6540571 L66.3605714,15.6850857 L63.7388571,15.6850857 L63.7388571,0.00249941429 L66.5168571,0.00249941429 L66.5182857,0.00249941429 Z M71.9957143,12.5270571 C72.5705714,11.7959714 72.858,10.7949714 72.858,9.52525714 C72.858,8.25557143 72.5705714,7.25454286 71.9957143,6.52345714 C71.4208571,5.7924 70.6322857,5.42622857 69.6311429,5.42622857 C68.6302857,5.42622857 67.8391429,5.7924 67.2568571,6.52345714 C66.6742857,7.2558 66.3831429,8.25682857 66.3831429,9.52525714 C66.3831429,10.7937143 66.6742857,11.7959714 67.2568571,12.5270571 C67.8391429,13.2594 68.6314286,13.6243143 69.6311429,13.6243143 C70.6308571,13.6243143 71.4194286,13.2581429 71.9957143,12.5270571 Z M79.6462857,0.00249941429 L79.6462857,2.39943714 L76.7331429,2.39943714 L76.7331429,0.00249941429 L79.6462857,0.00249941429 Z M79.58,3.36297143 L79.58,15.6863143 L76.802,15.6863143 L76.802,3.36297143 L79.58,3.36297143 Z M92.7082857,15.6863143 L90.0414286,15.6863143 L90.0414286,14.7003143 C89.0554286,15.5663429 87.8305714,16 86.3671429,16 C85.2474286,16 84.2614286,15.7350571 83.4105714,15.2052 C82.5594286,14.6753143 81.8982857,13.9204857 81.4271429,12.9419714 C80.9571429,11.9634571 80.7211429,10.8249714 80.7211429,9.52525714 C80.7211429,8.22557143 80.956,7.08708571 81.4271429,6.10857143 C81.8982857,5.13005714 82.5582857,4.37648571 83.4105714,3.84534286 C84.2614286,3.31548571 85.2474286,3.05054286 86.3671429,3.05054286 C87.8305714,3.05054286 89.0554286,3.48417143 90.0414286,4.35022857 L90.0414286,3.3642 L92.7082857,3.3642 L92.7082857,15.6875714 L92.7082857,15.6863143 Z M89.1917143,12.5270571 C89.774,11.7959714 90.0651429,10.7949714 90.0651429,9.52525714 C90.0651429,8.25557143 89.774,7.25454286 89.1917143,6.52345714 C88.6091429,5.7924 87.8168571,5.42622857 86.816,5.42622857 C85.8148571,5.42622857 85.0277143,5.7924 84.4528571,6.52345714 C83.8777143,7.2558 83.5902857,8.25682857 83.5902857,9.52525714 C83.5902857,10.7937143 83.8777143,11.7959714 84.4528571,12.5270571 C85.0277143,13.2594 85.8162857,13.6243143 86.816,13.6243143 C87.8157143,13.6243143 88.608,13.2581429 89.1917143,12.5270571 Z M2.28696286,0 L2.28696286,2.26446857 L0,2.26446857 L0,0 L2.28696286,0 Z M2.28696286,3.228 L2.28696286,7.50948571 L0,7.50948571 L0,3.228 L2.28696286,3.228 Z M2.28696286,8.49551429 L2.28696286,15.6913143 L0,15.6913143 L0,8.49551429 L2.28696286,8.49551429 Z M7.55448571,0 L7.55448571,2.26446857 L3.27298286,2.26446857 L3.27298286,0 L7.55448571,0 Z M7.55448571,3.228 L7.55448571,7.50948571 L3.27298286,7.50948571 L3.27298286,3.228 L7.55448571,3.228 Z M7.55448571,8.49551429 L7.55448571,15.6913143 L3.27298286,15.6913143 L3.27298286,8.49551429 L7.55448571,8.49551429 Z M15.6913143,0 L15.6913143,2.26446857 L8.518,2.26446857 L8.518,0 L15.6913143,0 Z M15.6913143,3.228 L15.6913143,7.50948571 L8.518,7.50948571 L8.518,3.228 L15.6913143,3.228 Z M15.6913143,8.49551429 L15.6913143,15.6913143 L8.518,15.6913143 L8.518,8.49551429 L15.6913143,8.49551429 Z" fill="currentColor"></path></svg></a><div class="flex items-center space-x-sm"><a href="/demo"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-brand hover:bg-button-brand-hover text-primary-invert">Book a demo</button></a><button class="aspect-square h-[16px] w-[16px] flex flex-col gap-[2px] items-center justify-center"><div class="w-[14px] h-[2px] bg-charcoal shrink-0 transition-all origin-center absolute rotate-0 translate-y-[-4px]"></div><div class="w-[14px] h-[2px] bg-charcoal shrink-0 transition-all origin-center absolute opacity-100"></div><div class="w-[14px] h-[2px] bg-charcoal shrink-0 transition-all origin-center absolute rotate-0 translate-y-[4px]"></div></button></div></div></div><div class="w-[11px] lg:w-rail border-l border-steel flex-shrink-0 flex-grow-0 h-full bg-marble"></div></div><nav class="
          transition-all bg-marble w-full ease-in-out fixed top-0
          flex border-steel overflow-hidden
          items-start justify-start align-top
          opacity-50 border-b-0
      " style="height:0px"><div class="w-[11px] lg:w-rail border-r border-steel flex-shrink-0 flex-grow-0 h-full bg-marble"></div><div class="flex-grow h-full bg-marble flex items-center"><ul class="px-sm py-md flex flex-col gap-md h-full"><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:100ms"><a href="/product">Product</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:120ms"><a href="/security">Security</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:140ms"><a href="/pricing">Pricing</a></li><div class="h-sm"></div><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:150ms"><h4 class="text-sm uppercase text-secondary">Company</h4></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:160ms"><a href="/about">About</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:170ms"><a href="/blog">Blog</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:180ms"><a href="/newsroom">Newsroom</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:190ms"><a href="/careers">Careers</a></li></ul></div><div class="w-[11px] lg:w-rail border-l border-steel flex-shrink-0 flex-grow-0 h-full bg-marble"></div></nav></nav><nav class="hidden lg:block fixed z-40 top-0 w-full transition-opacity" style="margin-top:0px;opacity:0"><div class="
          w-full h-full absolute transition-all z-10
          false
        " style="opacity:1"></div><div class="mx-sm lg:mx-rail xl:mx-3xl z-20 relative"><div class="
            max-w-1660 mx-auto px-md py-md flex justify-between
            border-l border-r items-center
            border-transparent
          " id="main-nav"><span class="transition-all text-primary-invert" style="transform:translateX(-0px)"><a class="xl:hidden relative flex" href="/"><div style="opacity:1"><svg width="93" height="16" viewBox="0 0 93 16" version="1.1" xmlns="http://www.w3.org/2000/svg"><title>Hebbia</title><path d="M25.9426571,0.00249941429 L25.9426571,6.40974286 L33.7397143,6.40974286 L33.7397143,0.00249941429 L36.6077143,0.00249941429 L36.6077143,15.6863143 L33.7397143,15.6863143 L33.7397143,9.23408571 L25.9426571,9.23408571 L25.9426571,15.6863143 L23.0746,15.6863143 L23.0746,0.00249941429 L25.9426571,0.00249941429 Z M41.4914286,12.8744857 C42.0288571,13.4043714 42.7688571,13.6692857 43.7097143,13.6692857 C44.4271429,13.6692857 45.0245714,13.5280857 45.5017143,13.2431429 C45.9791429,12.9594571 46.3228571,12.5483143 46.5328571,12.0109429 L49.4234286,12.0109429 C49.1248571,13.1906571 48.4637143,14.1504286 47.44,14.8902571 C46.4165714,15.6300857 45.1657143,15.9987429 43.6871429,15.9987429 C42.4925714,15.9987429 41.4391429,15.7300571 40.528,15.1926857 C39.6168571,14.6553143 38.9145714,13.8967429 38.4222857,12.9182286 C37.93,11.9397143 37.6822857,10.8087143 37.6822857,9.52402857 C37.6822857,8.23931429 37.9285714,7.10834286 38.4222857,6.1298 C38.9145714,5.15128571 39.6131429,4.39397143 40.5168571,3.85534286 C41.4202857,3.31797143 42.4625714,3.04928571 43.6422857,3.04928571 C44.822,3.04928571 45.8642857,3.31797143 46.7677143,3.85534286 C47.6714286,4.39271429 48.37,5.15128571 48.8622857,6.1298 C49.3545714,7.10834286 49.602,8.23931429 49.602,9.52402857 C49.602,9.89768571 49.5797143,10.2563429 49.5345714,10.6000286 L40.4831429,10.6000286 C40.618,11.5860286 40.9542857,12.3446 41.4914286,12.8744857 Z M46.824,8.26931429 C46.5102857,6.34225714 45.4494286,5.37874286 43.6422857,5.37874286 C42.7611429,5.37874286 42.0588571,5.63242857 41.5365714,6.14105714 C41.0128571,6.64842857 40.6705714,7.35828571 40.5054286,8.26931429 L46.824,8.26931429 Z M53.4548571,0.00249941429 L53.4548571,4.259 C54.4108571,3.45294286 55.5982857,3.04928571 57.018,3.04928571 C58.1377143,3.04928571 59.1237143,3.31422857 59.976,3.84408571 C60.8271429,4.37397143 61.488,5.1288 61.9591429,6.10731429 C62.4302857,7.08582857 62.6654286,8.22431429 62.6654286,9.52402857 C62.6654286,10.8237143 62.4302857,11.9622 61.9591429,12.9407143 C61.4894286,13.9192286 60.8282857,14.6740571 59.976,15.2039429 C59.1237143,15.7338 58.1388571,15.9987429 57.018,15.9987429 C55.5094286,15.9987429 54.2697143,15.5501143 53.2988571,14.6540571 L53.2988571,15.6850857 L50.6768571,15.6850857 L50.6768571,0.00249941429 L53.4548571,0.00249941429 Z M58.9337143,12.5270571 C59.5085714,11.7959714 59.796,10.7949714 59.796,9.52525714 C59.796,8.25557143 59.5085714,7.25454286 58.9337143,6.52345714 C58.3588571,5.7924 57.5702857,5.42622857 56.5705714,5.42622857 C55.5708571,5.42622857 54.7782857,5.7924 54.196,6.52345714 C53.6137143,7.2558 53.3225714,8.25682857 53.3225714,9.52525714 C53.3225714,10.7937143 53.6137143,11.7959714 54.196,12.5270571 C54.7782857,13.2594 55.5708571,13.6243143 56.5705714,13.6243143 C57.5702857,13.6243143 58.3588571,13.2581429 58.9337143,12.5270571 Z M66.5182857,0.00249941429 L66.5182857,4.259 C67.4742857,3.45294286 68.6614286,3.04928571 70.0797143,3.04928571 C71.1994286,3.04928571 72.1857143,3.31422857 73.038,3.84408571 C73.8888571,4.37397143 74.55,5.1288 75.0211429,6.10731429 C75.4911429,7.08582857 75.7271429,8.22431429 75.7271429,9.52402857 C75.7271429,10.8237143 75.4922857,11.9622 75.0211429,12.9407143 C74.55,13.9192286 73.8888571,14.6740571 73.038,15.2039429 C72.1868571,15.7338 71.2008571,15.9987429 70.0797143,15.9987429 C68.5714286,15.9987429 67.3317143,15.5501143 66.3605714,14.6540571 L66.3605714,15.6850857 L63.7388571,15.6850857 L63.7388571,0.00249941429 L66.5168571,0.00249941429 L66.5182857,0.00249941429 Z M71.9957143,12.5270571 C72.5705714,11.7959714 72.858,10.7949714 72.858,9.52525714 C72.858,8.25557143 72.5705714,7.25454286 71.9957143,6.52345714 C71.4208571,5.7924 70.6322857,5.42622857 69.6311429,5.42622857 C68.6302857,5.42622857 67.8391429,5.7924 67.2568571,6.52345714 C66.6742857,7.2558 66.3831429,8.25682857 66.3831429,9.52525714 C66.3831429,10.7937143 66.6742857,11.7959714 67.2568571,12.5270571 C67.8391429,13.2594 68.6314286,13.6243143 69.6311429,13.6243143 C70.6308571,13.6243143 71.4194286,13.2581429 71.9957143,12.5270571 Z M79.6462857,0.00249941429 L79.6462857,2.39943714 L76.7331429,2.39943714 L76.7331429,0.00249941429 L79.6462857,0.00249941429 Z M79.58,3.36297143 L79.58,15.6863143 L76.802,15.6863143 L76.802,3.36297143 L79.58,3.36297143 Z M92.7082857,15.6863143 L90.0414286,15.6863143 L90.0414286,14.7003143 C89.0554286,15.5663429 87.8305714,16 86.3671429,16 C85.2474286,16 84.2614286,15.7350571 83.4105714,15.2052 C82.5594286,14.6753143 81.8982857,13.9204857 81.4271429,12.9419714 C80.9571429,11.9634571 80.7211429,10.8249714 80.7211429,9.52525714 C80.7211429,8.22557143 80.956,7.08708571 81.4271429,6.10857143 C81.8982857,5.13005714 82.5582857,4.37648571 83.4105714,3.84534286 C84.2614286,3.31548571 85.2474286,3.05054286 86.3671429,3.05054286 C87.8305714,3.05054286 89.0554286,3.48417143 90.0414286,4.35022857 L90.0414286,3.3642 L92.7082857,3.3642 L92.7082857,15.6875714 L92.7082857,15.6863143 Z M89.1917143,12.5270571 C89.774,11.7959714 90.0651429,10.7949714 90.0651429,9.52525714 C90.0651429,8.25557143 89.774,7.25454286 89.1917143,6.52345714 C88.6091429,5.7924 87.8168571,5.42622857 86.816,5.42622857 C85.8148571,5.42622857 85.0277143,5.7924 84.4528571,6.52345714 C83.8777143,7.2558 83.5902857,8.25682857 83.5902857,9.52525714 C83.5902857,10.7937143 83.8777143,11.7959714 84.4528571,12.5270571 C85.0277143,13.2594 85.8162857,13.6243143 86.816,13.6243143 C87.8157143,13.6243143 88.608,13.2581429 89.1917143,12.5270571 Z M2.28696286,0 L2.28696286,2.26446857 L0,2.26446857 L0,0 L2.28696286,0 Z M2.28696286,3.228 L2.28696286,7.50948571 L0,7.50948571 L0,3.228 L2.28696286,3.228 Z M2.28696286,8.49551429 L2.28696286,15.6913143 L0,15.6913143 L0,8.49551429 L2.28696286,8.49551429 Z M7.55448571,0 L7.55448571,2.26446857 L3.27298286,2.26446857 L3.27298286,0 L7.55448571,0 Z M7.55448571,3.228 L7.55448571,7.50948571 L3.27298286,7.50948571 L3.27298286,3.228 L7.55448571,3.228 Z M7.55448571,8.49551429 L7.55448571,15.6913143 L3.27298286,15.6913143 L3.27298286,8.49551429 L7.55448571,8.49551429 Z M15.6913143,0 L15.6913143,2.26446857 L8.518,2.26446857 L8.518,0 L15.6913143,0 Z M15.6913143,3.228 L15.6913143,7.50948571 L8.518,7.50948571 L8.518,3.228 L15.6913143,3.228 Z M15.6913143,8.49551429 L15.6913143,15.6913143 L8.518,15.6913143 L8.518,8.49551429 L15.6913143,8.49551429 Z" fill="currentColor"></path></svg></div><span class="absolute top-[0px] left-[0px] opacity-0" style="opacity:0"><svg width="16" height="16" viewBox="0 0 16 16"><title>Hebbia</title><g fill="currentColor" fill-rule="nonzero"><path d="M2.28696286,0 L2.28696286,2.26446857 L0,2.26446857 L0,0 L2.28696286,0 Z M2.28696286,3.228 L2.28696286,7.50948571 L0,7.50948571 L0,3.228 L2.28696286,3.228 Z M2.28696286,8.49551429 L2.28696286,15.6913143 L0,15.6913143 L0,8.49551429 L2.28696286,8.49551429 Z M7.55448571,0 L7.55448571,2.26446857 L3.27298286,2.26446857 L3.27298286,0 L7.55448571,0 Z M7.55448571,3.228 L7.55448571,7.50948571 L3.27298286,7.50948571 L3.27298286,3.228 L7.55448571,3.228 Z M7.55448571,8.49551429 L7.55448571,15.6913143 L3.27298286,15.6913143 L3.27298286,8.49551429 L7.55448571,8.49551429 Z M15.6913143,0 L15.6913143,2.26446857 L8.518,2.26446857 L8.518,0 L15.6913143,0 Z M15.6913143,3.228 L15.6913143,7.50948571 L8.518,7.50948571 L8.518,3.228 L15.6913143,3.228 Z M15.6913143,8.49551429 L15.6913143,15.6913143 L8.518,15.6913143 L8.518,8.49551429 L15.6913143,8.49551429 Z" id="Shape"></path></g></svg></span></a><a class="hidden xl:inline-block" href="/"><svg width="93" height="16" viewBox="0 0 93 16" version="1.1" xmlns="http://www.w3.org/2000/svg"><title>Hebbia</title><path d="M25.9426571,0.00249941429 L25.9426571,6.40974286 L33.7397143,6.40974286 L33.7397143,0.00249941429 L36.6077143,0.00249941429 L36.6077143,15.6863143 L33.7397143,15.6863143 L33.7397143,9.23408571 L25.9426571,9.23408571 L25.9426571,15.6863143 L23.0746,15.6863143 L23.0746,0.00249941429 L25.9426571,0.00249941429 Z M41.4914286,12.8744857 C42.0288571,13.4043714 42.7688571,13.6692857 43.7097143,13.6692857 C44.4271429,13.6692857 45.0245714,13.5280857 45.5017143,13.2431429 C45.9791429,12.9594571 46.3228571,12.5483143 46.5328571,12.0109429 L49.4234286,12.0109429 C49.1248571,13.1906571 48.4637143,14.1504286 47.44,14.8902571 C46.4165714,15.6300857 45.1657143,15.9987429 43.6871429,15.9987429 C42.4925714,15.9987429 41.4391429,15.7300571 40.528,15.1926857 C39.6168571,14.6553143 38.9145714,13.8967429 38.4222857,12.9182286 C37.93,11.9397143 37.6822857,10.8087143 37.6822857,9.52402857 C37.6822857,8.23931429 37.9285714,7.10834286 38.4222857,6.1298 C38.9145714,5.15128571 39.6131429,4.39397143 40.5168571,3.85534286 C41.4202857,3.31797143 42.4625714,3.04928571 43.6422857,3.04928571 C44.822,3.04928571 45.8642857,3.31797143 46.7677143,3.85534286 C47.6714286,4.39271429 48.37,5.15128571 48.8622857,6.1298 C49.3545714,7.10834286 49.602,8.23931429 49.602,9.52402857 C49.602,9.89768571 49.5797143,10.2563429 49.5345714,10.6000286 L40.4831429,10.6000286 C40.618,11.5860286 40.9542857,12.3446 41.4914286,12.8744857 Z M46.824,8.26931429 C46.5102857,6.34225714 45.4494286,5.37874286 43.6422857,5.37874286 C42.7611429,5.37874286 42.0588571,5.63242857 41.5365714,6.14105714 C41.0128571,6.64842857 40.6705714,7.35828571 40.5054286,8.26931429 L46.824,8.26931429 Z M53.4548571,0.00249941429 L53.4548571,4.259 C54.4108571,3.45294286 55.5982857,3.04928571 57.018,3.04928571 C58.1377143,3.04928571 59.1237143,3.31422857 59.976,3.84408571 C60.8271429,4.37397143 61.488,5.1288 61.9591429,6.10731429 C62.4302857,7.08582857 62.6654286,8.22431429 62.6654286,9.52402857 C62.6654286,10.8237143 62.4302857,11.9622 61.9591429,12.9407143 C61.4894286,13.9192286 60.8282857,14.6740571 59.976,15.2039429 C59.1237143,15.7338 58.1388571,15.9987429 57.018,15.9987429 C55.5094286,15.9987429 54.2697143,15.5501143 53.2988571,14.6540571 L53.2988571,15.6850857 L50.6768571,15.6850857 L50.6768571,0.00249941429 L53.4548571,0.00249941429 Z M58.9337143,12.5270571 C59.5085714,11.7959714 59.796,10.7949714 59.796,9.52525714 C59.796,8.25557143 59.5085714,7.25454286 58.9337143,6.52345714 C58.3588571,5.7924 57.5702857,5.42622857 56.5705714,5.42622857 C55.5708571,5.42622857 54.7782857,5.7924 54.196,6.52345714 C53.6137143,7.2558 53.3225714,8.25682857 53.3225714,9.52525714 C53.3225714,10.7937143 53.6137143,11.7959714 54.196,12.5270571 C54.7782857,13.2594 55.5708571,13.6243143 56.5705714,13.6243143 C57.5702857,13.6243143 58.3588571,13.2581429 58.9337143,12.5270571 Z M66.5182857,0.00249941429 L66.5182857,4.259 C67.4742857,3.45294286 68.6614286,3.04928571 70.0797143,3.04928571 C71.1994286,3.04928571 72.1857143,3.31422857 73.038,3.84408571 C73.8888571,4.37397143 74.55,5.1288 75.0211429,6.10731429 C75.4911429,7.08582857 75.7271429,8.22431429 75.7271429,9.52402857 C75.7271429,10.8237143 75.4922857,11.9622 75.0211429,12.9407143 C74.55,13.9192286 73.8888571,14.6740571 73.038,15.2039429 C72.1868571,15.7338 71.2008571,15.9987429 70.0797143,15.9987429 C68.5714286,15.9987429 67.3317143,15.5501143 66.3605714,14.6540571 L66.3605714,15.6850857 L63.7388571,15.6850857 L63.7388571,0.00249941429 L66.5168571,0.00249941429 L66.5182857,0.00249941429 Z M71.9957143,12.5270571 C72.5705714,11.7959714 72.858,10.7949714 72.858,9.52525714 C72.858,8.25557143 72.5705714,7.25454286 71.9957143,6.52345714 C71.4208571,5.7924 70.6322857,5.42622857 69.6311429,5.42622857 C68.6302857,5.42622857 67.8391429,5.7924 67.2568571,6.52345714 C66.6742857,7.2558 66.3831429,8.25682857 66.3831429,9.52525714 C66.3831429,10.7937143 66.6742857,11.7959714 67.2568571,12.5270571 C67.8391429,13.2594 68.6314286,13.6243143 69.6311429,13.6243143 C70.6308571,13.6243143 71.4194286,13.2581429 71.9957143,12.5270571 Z M79.6462857,0.00249941429 L79.6462857,2.39943714 L76.7331429,2.39943714 L76.7331429,0.00249941429 L79.6462857,0.00249941429 Z M79.58,3.36297143 L79.58,15.6863143 L76.802,15.6863143 L76.802,3.36297143 L79.58,3.36297143 Z M92.7082857,15.6863143 L90.0414286,15.6863143 L90.0414286,14.7003143 C89.0554286,15.5663429 87.8305714,16 86.3671429,16 C85.2474286,16 84.2614286,15.7350571 83.4105714,15.2052 C82.5594286,14.6753143 81.8982857,13.9204857 81.4271429,12.9419714 C80.9571429,11.9634571 80.7211429,10.8249714 80.7211429,9.52525714 C80.7211429,8.22557143 80.956,7.08708571 81.4271429,6.10857143 C81.8982857,5.13005714 82.5582857,4.37648571 83.4105714,3.84534286 C84.2614286,3.31548571 85.2474286,3.05054286 86.3671429,3.05054286 C87.8305714,3.05054286 89.0554286,3.48417143 90.0414286,4.35022857 L90.0414286,3.3642 L92.7082857,3.3642 L92.7082857,15.6875714 L92.7082857,15.6863143 Z M89.1917143,12.5270571 C89.774,11.7959714 90.0651429,10.7949714 90.0651429,9.52525714 C90.0651429,8.25557143 89.774,7.25454286 89.1917143,6.52345714 C88.6091429,5.7924 87.8168571,5.42622857 86.816,5.42622857 C85.8148571,5.42622857 85.0277143,5.7924 84.4528571,6.52345714 C83.8777143,7.2558 83.5902857,8.25682857 83.5902857,9.52525714 C83.5902857,10.7937143 83.8777143,11.7959714 84.4528571,12.5270571 C85.0277143,13.2594 85.8162857,13.6243143 86.816,13.6243143 C87.8157143,13.6243143 88.608,13.2581429 89.1917143,12.5270571 Z M2.28696286,0 L2.28696286,2.26446857 L0,2.26446857 L0,0 L2.28696286,0 Z M2.28696286,3.228 L2.28696286,7.50948571 L0,7.50948571 L0,3.228 L2.28696286,3.228 Z M2.28696286,8.49551429 L2.28696286,15.6913143 L0,15.6913143 L0,8.49551429 L2.28696286,8.49551429 Z M7.55448571,0 L7.55448571,2.26446857 L3.27298286,2.26446857 L3.27298286,0 L7.55448571,0 Z M7.55448571,3.228 L7.55448571,7.50948571 L3.27298286,7.50948571 L3.27298286,3.228 L7.55448571,3.228 Z M7.55448571,8.49551429 L7.55448571,15.6913143 L3.27298286,15.6913143 L3.27298286,8.49551429 L7.55448571,8.49551429 Z M15.6913143,0 L15.6913143,2.26446857 L8.518,2.26446857 L8.518,0 L15.6913143,0 Z M15.6913143,3.228 L15.6913143,7.50948571 L8.518,7.50948571 L8.518,3.228 L15.6913143,3.228 Z M15.6913143,8.49551429 L15.6913143,15.6913143 L8.518,15.6913143 L8.518,8.49551429 L15.6913143,8.49551429 Z" fill="currentColor"></path></svg><span class="absolute top-[0px] left-[0px] opacity-0"><svg width="16" height="16" viewBox="0 0 16 16"><title>Hebbia</title><g fill="currentColor" fill-rule="nonzero"><path d="M2.28696286,0 L2.28696286,2.26446857 L0,2.26446857 L0,0 L2.28696286,0 Z M2.28696286,3.228 L2.28696286,7.50948571 L0,7.50948571 L0,3.228 L2.28696286,3.228 Z M2.28696286,8.49551429 L2.28696286,15.6913143 L0,15.6913143 L0,8.49551429 L2.28696286,8.49551429 Z M7.55448571,0 L7.55448571,2.26446857 L3.27298286,2.26446857 L3.27298286,0 L7.55448571,0 Z M7.55448571,3.228 L7.55448571,7.50948571 L3.27298286,7.50948571 L3.27298286,3.228 L7.55448571,3.228 Z M7.55448571,8.49551429 L7.55448571,15.6913143 L3.27298286,15.6913143 L3.27298286,8.49551429 L7.55448571,8.49551429 Z M15.6913143,0 L15.6913143,2.26446857 L8.518,2.26446857 L8.518,0 L15.6913143,0 Z M15.6913143,3.228 L15.6913143,7.50948571 L8.518,7.50948571 L8.518,3.228 L15.6913143,3.228 Z M15.6913143,8.49551429 L15.6913143,15.6913143 L8.518,15.6913143 L8.518,8.49551429 L15.6913143,8.49551429 Z" id="Shape"></path></g></svg></span></a></span><div class="flex flex-row gap-sm lg:gap-md transition-all _nav-links" style="opacity:1"><a class="
        _link
        text-button uppercase py-xs px-xs lg:px-sm rounded-md transition-all tracking-lg
        text-secondary-invert 
        group-hover:text-primary group-hover:bg-sand
        hover:text-primary-brand hover:bg-offwhite 
        undefined
      " href="/product">Product</a><div class="group"><a class="
        _link
        text-button uppercase py-xs px-xs lg:px-sm rounded-md transition-all tracking-lg
        text-secondary-invert 
        group-hover:text-primary group-hover:bg-sand
        hover:text-primary-brand hover:bg-offwhite 
        undefined
      " href="/industry/finance">Solutions</a><div class="
        fixed z-20 w-full h-full transition-all left-[0px]
        pointer-events-none opacity-0
        false
        _panel
      "><div class="w-full h-full absolute bg-charcoal opacity-50 top-0 mt-md"></div><div class="bg-marble z-10 relative border-steel border-b mt-md border-t"><div class="mx-sm sm:mx-rail xl:mx-3xl z-20 relative"><div class="
              max-w-1660 mx-auto px-md py-md flex justify-between
              border-l border-r items-center
              border-steel
            " style="padding-left:0px"><div class="flex flex-row justify-between items-start w-full pb-lg"><ul class="flex flex-col gap-sm text-sm"><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:100ms"><h4 class="text-button uppercase text-secondary">By Industry</h4></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:120ms"><a class="text-sm" href="/industry/finance">For Finance</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:140ms"><a class="text-sm" href="/industry/law">For Law</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:160ms"><a class="text-sm" href="/industry/corporate">For Corporate</a></li></ul></div></div></div></div></div></div><div class="group"><a class="
        _link
        text-button uppercase py-xs px-xs lg:px-sm rounded-md transition-all tracking-lg
        text-secondary-invert 
        group-hover:text-primary group-hover:bg-sand
        hover:text-primary-brand hover:bg-offwhite 
        undefined
      " href="/about">Company</a><div class="
        fixed z-20 w-full h-full transition-all left-[0px]
        pointer-events-none opacity-0
        false
        _panel
      "><div class="w-full h-full absolute bg-charcoal opacity-50 top-0 mt-md"></div><div class="bg-marble z-10 relative border-steel border-b mt-md border-t"><div class="mx-sm sm:mx-rail xl:mx-3xl z-20 relative"><div class="
              max-w-1660 mx-auto px-md py-md flex justify-between
              border-l border-r items-center
              border-steel
            " style="padding-left:0px"><div class="flex flex-row justify-between items-start w-full pb-lg gap-md"><ul class="flex flex-col gap-sm text-sm"><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:100ms"><h4 class="text-button uppercase text-secondary">Company</h4></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:120ms"><a class="text-sm" href="/about">About</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:140ms"><a class="text-sm" href="/blog">Blog</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:160ms"><a class="text-sm" href="/newsroom">Newsroom</a></li><li class="
        transition-all text-md
        opacity-0 -translate-y-xl
      " style="transition-delay:180ms"><a class="text-sm" href="/careers">Careers</a></li></ul></div></div></div></div></div></div><a class="
        _link
        text-button uppercase py-xs px-xs lg:px-sm rounded-md transition-all tracking-lg
        text-secondary-invert 
        group-hover:text-primary group-hover:bg-sand
        hover:text-primary-brand hover:bg-offwhite 
        undefined
      " href="/security">Security</a><a class="
        _link
        text-button uppercase py-xs px-xs lg:px-sm rounded-md transition-all tracking-lg
        text-secondary-invert 
        group-hover:text-primary group-hover:bg-sand
        hover:text-primary-brand hover:bg-offwhite 
        undefined
      " href="/pricing">Pricing</a></div><div class="flex items-center space-x-xs"><span class="transition-all" style="opacity:1"><a href="/careers"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-offwhite hover:bg-button-offwhite-hover text-primary">Careers</button></a></span><span class="transition-all" style="opacity:1"><a href="https://search.hebbia.ai"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-offwhite hover:bg-button-offwhite-hover text-primary">Sign In</button></a></span><span class="transition-all origin-left" style="transform:translateX(0px)"><a href="/demo"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-brand hover:bg-button-brand-hover text-primary-invert">Book a demo</button></a></span></div></div></div></nav></header><section data-nav-color="primary" class="border-t border-steel bg-marble"><div class="mx-sm lg:mx-rail xl:mx-3xl"><div class="max-w-full xl:max-w-1660 mx-auto"><div class="border-l border-r border-steel"><div class="pt-2xl pb-xl"><header class="flex flex-col gap-sm px-md"><h1 class="text-xl">Blog</h1><h4 class="text-secondary text-sm max-w-[440px]">How Hebbia is leading the way in building<br/> AI for finance</h4></header><article class="p-md pt-xl"><a href="/blog/why-i-joined-hebbia-as-cto"><img alt="Why I Joined Hebbia as CTO cover image" loading="lazy" width="1600" height="1600" decoding="async" data-nimg="1" class="w-full aspect-[1340/660] object-cover" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fbn476u6z5acg%2F2L9hL6k5F9fO74Wc4ZTbsN%2F0d9ce31d4aa53b56cc8a9898851eed66%2F1024_Blog_Aabhas_CoverImage_1200x600.png&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fbn476u6z5acg%2F2L9hL6k5F9fO74Wc4ZTbsN%2F0d9ce31d4aa53b56cc8a9898851eed66%2F1024_Blog_Aabhas_CoverImage_1200x600.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fbn476u6z5acg%2F2L9hL6k5F9fO74Wc4ZTbsN%2F0d9ce31d4aa53b56cc8a9898851eed66%2F1024_Blog_Aabhas_CoverImage_1200x600.png&amp;w=3840&amp;q=75"/></a><div class="flex flex-row gap-sm items-center py-md"><div class="border-cobalt inline-block leading-none border text-primary-brand text-xxxs tracking-[0.01em] font-medium uppercase rounded-md py-[3px] px-[6px] text-white">Company</div><span class="text-secondary text-xxxs tracking-[0.01em] font-medium uppercase">10.21.25</span><span class="text-secondary text-xxxs tracking-[0.01em] font-medium uppercase">Aabhas Sharma</span></div><div class="flex flex-col sm:flex-row justify-between gap-sm"><div class="w-full sm:w-1/2 flex flex-col gap-sm"><h2 class="text-lg"><a href="/blog/why-i-joined-hebbia-as-cto">Why I Joined Hebbia as CTO</a></h2></div><div class="w-full sm:w-1/2 flex flex-col gap-sm"><a href="/blog/why-i-joined-hebbia-as-cto"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-brand hover:bg-button-brand-hover text-primary-invert">Read More</button></a></div></div></article></div></div></div></div></section><footer data-nav-color="inverted" class="bg-charcoal border-t border-steel text-primary-invert"><div><div class="mx-sm lg:mx-rail xl:mx-3xl"><div class="max-w-full xl:max-w-1660 mx-auto"><div class="border-l border-r border-steel"><div><div class="p-md"><div class="logo"><svg width="36" height="36" viewBox="0 0 36 36" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H6V6H0V0ZM9 6H18V0H9V6ZM21 0V6H36V0H21ZM0 18H6V9H0V18ZM9 18H18V9H9V18ZM21 18H36V9H21V18ZM0 36H6V21H0V36ZM9 36H18V21H9V36ZM21 36H36V21H21V36Z" fill="#F5F5F5"></path></svg></div><div class="lg:grid lg:grid-cols-2 gap-lg mt-[140px] lg:mt-[280px]"><div><p class="max-w-[600px] tracking-xxxs text-xl">Unlock the power of AI for your firm.</p></div><div class="mt-md flex justify-end flex-col lg:mt-none"><div><p class="text-xs max-w-[390px]">Matrix works from day one – no in-house development or fine-tuning needed.</p><div class="mt-md"><a href="/demo"><button type="button" class="leading-none text-button whitespace-nowrap tracking-lg font-medium uppercase rounded-sm h-[24px] px-[8px] text-white bg-button-brand hover:bg-button-brand-hover text-primary-invert">Book a Demo</button></a></div></div></div></div></div></div></div></div></div></div><div class="border-t border-steel"><div class="mx-sm lg:mx-rail xl:mx-3xl"><div class="max-w-full xl:max-w-1660 mx-auto"><div class="border-l border-r border-steel"><div class="p-md"><div class="pt-xl lg:pt-2xl gap-lg lg:grid lg:grid-cols-2"><div class="h-full flex flex-col justify-end"><p class="text-xs lg:text-xxs whitespace-pre">Hebbia
233 Spring Street
New York, NY </p></div><div><ul class="text-xs flex space-x-md lg:-mb-xs lg:block lg:space-x-none lg:mt-none mt-md lg:text-xxs"><li><a class="hover:opacity-75 inline-block py-xs hover:underline" target="__blank" href="https://x.com/HebbiaAI">X</a></li><li><a class="hover:opacity-75 inline-block py-xs hover:underline" target="__blank" href="https://www.linkedin.com/company/hebbia">LinkedIn</a></li><li><a class="hover:opacity-75 inline-block py-xs hover:underline" target="__blank" href="https://www.instagram.com/hebbia">Instagram</a></li><li><a class="hover:opacity-75 inline-block py-xs hover:underline" target="__blank" href="/careers">Careers</a></li></ul></div></div></div></div></div></div></div><div class="border-t border-b border-steel"><div class="mx-sm lg:mx-rail xl:mx-3xl"><div class="max-w-full xl:max-w-1660 mx-auto"><div class="border-l border-r border-steel"><div class="py-md lg:py-sm px-md lg:flex lg:justify-between"><ul class="text-xs space-y-sm lg:space-y-none lg:text-xxs lg:flex lg:space-x-md"><li class="block lg:inline-block"><a class="hover:opacity-75 hover:underline" href="/terms-of-service">Terms of Service</a></li><li class="block lg:inline-block"><a class="hover:opacity-75 hover:underline" href="/acceptable-use">Acceptable Use Policy</a></li><li class="block lg:inline-block"><a class="hover:opacity-75 hover:underline" href="/privacy">Privacy Policy</a></li><li class="block lg:inline-block"><button>Cookie Preferences</button></li></ul><div class="text-xs mt-md lg:mt-none lg:text-xxs text-secondary">© Copyright <!-- -->2025<!-- --> Hebbia, Inc. All rights reserved.</div></div></div></div></div></div><div><div class="mx-sm lg:mx-rail xl:mx-3xl"><div class="max-w-full xl:max-w-1660 mx-auto"><div class="border-l border-r border-steel"><div class="h-sm sm:h-md md:h-lg"></div></div></div></div></div></footer></main><script src="/_next/static/chunks/webpack-41f05cabd64f3f4d.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/1b228b4a0c384dad-s.p.woff\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff\"}]\n2:HL[\"/_next/static/media/77230bf07519a880-s.p.woff\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff\"}]\n3:HL[\"/_next/static/media/e4e2fb3a0f27f527-s.p.woff\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff\"}]\n4:HL[\"/_next/static/css/ecd420d635265f57.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[2846,[],\"\"]\n8:I[4707,[],\"\"]\n9:I[6038,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"774\",\"static/chunks/app/blog/error-77f9f1c60163c1f3.js\"],\"default\"]\na:I[6423,[],\"\"]\nd:I[1060,[],\"\"]\ne:[]\n0:[\"$\",\"$L5\",null,{\"buildId\":\"haKg5rfBSLYvybr0S0Hds\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"blog\"],\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\",null],null],null]},[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$9\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ecd420d635265f57.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],\"$Lb\"],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"AI for Finance.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"manifest\",\"href\":\"/manifest.webmanifest\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"link\",\"5\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"32x32\"}],[\"$\",\"link\",\"6\",{\"rel\":\"icon\",\"href\":\"/icon.svg?104043f64f056642\",\"type\":\"image/svg+xml\",\"sizes\":\"any\"}],[\"$\",\"link\",\"7\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?1a5fcb960187c387\",\"type\":\"image/png\",\"sizes\":\"180x180\"}],[\"$\",\"meta\",\"8\",{\"name\":\"next-size-adjust\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"f:I[8003,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"\"]\n10:I[8087,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"GoogleTagManager\"]\n11:I[3357,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"default\"]\n12:I[5819,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"default\"]\n13:I[3793,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"default\"]\n14:I[1307,[\"320\",\"static/chunks/320-9ffc19bff26ffb6d.js\",\"185\",\"static/chunks/app/layout-8c37041e3ac03a0c.js\"],\"default\"]\n15:I[775,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"878\",\"static/chunks/878-9f3534a968d14183.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"160\",\"static/chunks/app/not-found-fc6c331b82e3041a.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_490f46 font-sans text-primary bg-white\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"$Lf\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"(function(){var a=window.mutiny=window.mutiny||{};if(!window.mutiny.client){a.client={_queue:{}};var b=[\\\"identify\\\",\\\"trackConversion\\\"];var c=[].concat(b,[\\\"defaultOptOut\\\",\\\"optOut\\\",\\\"optIn\\\"]);var d=function factory(c){return function(){for(var d=arguments.length,e=new Array(d),f=0;f\u003cd;f++){e[f]=arguments[f]}a.client._queue[c]=a.client._queue[c]||[];if(b.includes(c)){return new Promise(function(b,d){a.client._queue[c].push({args:e,resolve:b,reject:d})})}else{a.client._queue[c].push({args:e})}}};c.forEach(function(b){a.client[b]=d(b)})}})();\"},\"id\":\"mutiny-shim\",\"strategy\":\"beforeInteractive\"}],[\"$\",\"$Lf\",null,{\"id\":\"mutiny-client\",\"data-cfasync\":\"false\",\"strategy\":\"beforeInteractive\",\"src\":\"https://client-registry.mutinycdn.com/personalize/client/b59bc51867969ec5.js\"}],[\"$\",\"$L10\",null,{\"gtmId\":\"GTM-NMD54N7Z\"}],[\"$\",\"$Lf\",null,{\"id\":\"apollo\",\"children\":\"\\n          function initApollo(){var n=Math.random().toString(36).substring(7),o=document.createElement(\\\"script\\\");\\n          o.src=\\\"https://assets.apollo.io/micro/website-tracker/tracker.iife.js?nocache=\\\"+n,o.async=!0,o.defer=!0,\\n          o.onload=function(){window.trackingFunctions.onLoad({appId:\\\"663127b919d6500438b30395\\\"})},\\n          document.head.appendChild(o)}initApollo();          \\n        \"}],[\"$\",\"$L11\",null,{}],[\"$\",\"$L12\",null,{}],[\"$\",\"$Lf\",null,{\"src\":\"https://cmp.osano.com/169xbBUKm9qUnAu6o/efc596b5-cfb1-40eb-b39b-4212f85a9954/osano.js\"}],[\"$\",\"$Lf\",null,{\"id\":\"meta-pixel\",\"strategy\":\"afterInteractive\",\"dangerouslySetInnerHTML\":{\"__html\":\"\\n        !function(f,b,e,v,n,t,s)\\n        {if(f.fbq)return;n=f.fbq=function(){n.callMethod?\\n        n.callMethod.apply(n,arguments):n.queue.push(arguments)};\\n        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';\\n        n.queue=[];t=b.createElement(e);t.async=!0;\\n        t.src=v;s=b.getElementsByTagName(e)[0];\\n        s.parentNode.insertBefore(t,s)}(window, document,'script',\\n        'https://connect.facebook.net/en_US/fbevents.js');\\n        fbq('init', '1017907653595272');\\n        fbq('track', 'PageView');\\n      \"}}]]}],[\"$\",\"$L13\",null,{\"footer\":{\"address\":\"Hebbia\\n233 Spring Street\\nNew York, NY \",\"hero\":{\"image\":null,\"fullHeight\":false,\"headline\":\"Unlock the power of AI for your firm.\",\"subhead\":\"Matrix works from day one – no in-house development or fine-tuning needed.\",\"type\":\"custom\",\"actionsCollection\":{\"items\":[{\"text\":\"Book a Demo\",\"url\":\"/demo\"}]}}},\"children\":[\"$\",\"$L14\",null,{\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased cursor-default\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$L15\",null,{}],\"notFoundStyles\":[]}]}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"16:I[6060,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"878\",\"static/chunks/878-9f3534a968d14183.js\",\"106\",\"static/chunks/106-679e3fb3e86e138a.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"404\",\"static/chunks/app/blog/page-de45143c3e909f5e.js\"],\"default\"]\n17:I[2040,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"878\",\"static/chunks/878-9f3534a968d14183.js\",\"106\",\"static/chunks/106-679e3fb3e86e138a.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"404\",\"static/chunks/app/blog/page-de45143c3e909f5e.js\"],\"default\"]\n19:I[3606,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"878\",\"static/chunks/878-9f3534a968d14183.js\",\"106\",\"static/chunks/106-679e3fb3e86e138a.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"404\",\"static/chunks/app/blog/page-de45143c3e909f5e.js\"],\"default\"]\n1a:I[1665,[\"45\",\"static/chunks/45-fd881c86cc40ada7.js\",\"878\",\"static/chunks/878-9f3534a968d14183.js\",\"106\",\"static/chunks/106-679e3fb3e86e138a.js\",\"699\",\"static/chunks/699-646e730b035611b4.js\",\"404\",\"static/chunks/app/blog/page-de45143c3e909f5e.js\"],\"default\"]\n18:T4c4,Large language model (LLM) systems now sit at the heart of many enterprise workflows, yet the industry still lacks a principled, reproducible way to decide whether one prompt, model, or agentic configuration is genuinely better than another. We introduce Hebbia’s consensus-based evaluation framework—a statistically grounded, model-agnostic approach that scales from single-prompt tweaks to multi-agent orchestration. Building on prior work such as G-Eval, GPTScore, and BooookScore, we fuse long-context awareness with permutation-based hypothesis testing to minimize false positives while surfacing actionable signal for ML engineers. Alongside a full methodological walkthrough, we present a case study benchmarking popular OpenAI, Google, Grok, and Anthropic models across abstractive (reasoning and summarization) and extractive (exact string, term, and verbatim) tasks within the financial services industry. We found that when we validated our automated scores against human-labeled e"])</script><script>self.__next_f.push([1,"xamples from former hedge fund and private equity investors the results matched their expert opinion. More generally, our results highlight clear capability trade-offs that inform production model selection and agent design."])</script><script>self.__next_f.push([1,"7:[\"$\",\"main\",null,{\"children\":[[\"$\",\"$L16\",null,{}],[\"$\",\"$L17\",null,{\"blogPosts\":[{\"slug\":\"why-i-joined-hebbia-as-cto\",\"title\":\"Why I Joined Hebbia as CTO\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-10-21T00:00:00.000-04:00\",\"category\":\"Company\",\"author\":\"Aabhas Sharma\",\"excerpt\":null,\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2L9hL6k5F9fO74Wc4ZTbsN/0d9ce31d4aa53b56cc8a9898851eed66/1024_Blog_Aabhas_CoverImage_1200x600.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/772Xd94ymAJj6Po1WHHicp/9059742c1f0e9b07624e62f4d66d3e33/1024_Blog_Aabhas_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4f6OrsaJ6ssHCL5ElE7lgm/73ac9dac1a4c5235c58f0288e39ce9c3/1024_Blog_Aabhas_BlogHeader_1600x534.png\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A year ago, George Sivulka cold-reached me. That single message kicked off what would become the most thorough, deliberate career decision I've ever made.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This wasn't a quick \\\"let's grab coffee and see if there's a fit\\\" situation. This was a year-long process where I got to diligence every part of the business: the metrics, the customers, the technology, the vision.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I've done this before. Years ago, I spent months with Lauren Myrick, the CEO and founder of Found, before deciding to leave my role at Uber. When I first met Lauren, Found was pre-seed stage. By the time I joined as one of the first ten employees, they'd raised their Series A. I watched that company grow from Series A to Series C. That experience taught me what to look for: the signals that separate companies that will define categories from those that won't.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"So when I say leaving Found for Hebbia was a huge decision, I mean it. I needed to be \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"really\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" sure.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What I found over that year convinced me that this is where I needed to be.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Leader Who Gets It\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"George is relentless. I don't use that word lightly. Over the past year, I've watched him execute with an intensity that's rare even in Silicon Valley. But here's what really matters: he's relentless \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"and\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" humble. He's building this company with an openness to learning, growing, and changing as this market evolves that I've rarely seen in founders.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Most CEOs at this stage are either too rigid in their vision or too scattered in their execution. George is neither. He knows where we're going, but he's smart enough to adapt how we get there. That combination of clear vision with tactical flexibility is exactly what you need when you're building in a market that's literally being invented as we go.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Technical Challenge That Actually Matters\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Last month alone, we processed \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://www.hebbia.com/blog/hebbia-crosses-1-billion-pages-processed\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"more documents\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\" than we had in the entire history of the company.  We're talking exponential growth in complexity and scale.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We're investing heavily in our research arm. We're working on accuracy improvements, RLHF for generating end-user artifacts, fine-tuning for finance-specific models. These aren't incremental improvements. We're on the cusp of unlocking entirely new efficiencies in how AI completes GDP-accretive tasks. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"And we're moving beyond the Matrix. Our customers' needs have grown increasingly complex, and we're redefining fundamental paradigms of AI interfaces. Financial analysts who had only used ChatGPT are now processing tens of thousands of private documents and public filings with complex end-to-end workflows they’ve built in Hebbia every day. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The recent focus on finance has been particularly exciting. Investment banking and private capital are perfect use cases for our ability to ingest, understand, and act on massive document sets. We're making traditionally tedious tasks like diligence and investment research not just easier, but fundamentally different. We're even generating new signals to inform investment decisions and outperform the market.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Customers Who Validate Everything\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I spent the last few months meeting with Hebbia's customers. When you hear a managing director at a top-tier bank tell you that Hebbia has fundamentally changed how they work, that's not a testimonial. That's validation.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Humans are going to turn to AI as their first step for every task going forward. Between our unique presentation layer for complex workflows and the accuracy of our retrieval agents, we're positioned to be \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"the\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" tool that all workers use. This isn't hypothetical. It's already happening. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Board and The Timing\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I want to thank George, Mike Volpi, and Alex Immerman for their trust in bringing me on. Mike (from Index and now Hanabi) and Alex (from Andreessen) aren't just investors. They're partners who've seen this movie before. Spending time with them, understanding their vision for the company, seeing their conviction that we have the right team, the right leadership, and the right timing to capture this market: that sealed the deal for me.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"They gave me unprecedented access to everything I needed to make this decision. Every metric, every customer conversation, every strategic discussion. That level of transparency isn't just rare; it's a signal of how this company operates.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What's Next\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I'm running both tech and product, and we're building something special. We're opening our SF office, and we're going to rapidly grow our engineering, product, and design organization over the next year. We're hiring across all levels and disciplines.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This is a massive moment for Hebbia. The trajectory isn't just continuing. It's accelerating. The problems we're solving are hard, meaningful, and directly impact how millions of humans will do their jobs in the future.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Join Us\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"If you're an engineer who wants to work on genuinely difficult problems, if you're a product person who wants to redefine how an entire category of workers do their jobs, if you're a designer who wants to create interfaces for AI-native workflows that don't exist yet: we should talk.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Check out our \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://www.hebbia.com/careers\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"careers page \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\"or reach out to me directly. We're building the future of AI applications, and we need the best people to do it.\",\"marks\":[],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[]}}}},{\"slug\":\"the-disclosure-september-2025\",\"title\":\"The Disclosure: September 2025\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-10-09T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Hebbia Team\",\"excerpt\":\"We’ve released new Excel, PowerPoint, and Word generation features to help you build expert financial models and accelerate the process of presenting your ideas.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4P5MvpFFafy3vpnS3V9EBE/c3460c29fba1f18076a70f205c3056ed/93025_Blog_TheDisclosure_Sep_CoverImage_1200x600__2_.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/ozlV5mC9x0PmDgn9KvtEj/8ca84fcf9692ef46b1cc1fea22e006d1/93025_Blog_TheDisclosure_Sep_Thumbnail_1063x1080__1_.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/1VJcK7Wd7GaRYNGcBOKBYS/d05fe0292f0c2651104cbe8d6f071163/93025_Blog_TheDisclosure_Sep_Blogheader_1600x535__2_.png\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We’re advancing our mission: helping customers generate novel insights and act more quickly. We’ve released new \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Excel, PowerPoint, and Word generation\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" features to help you build expert financial models and accelerate the process of presenting your ideas.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Drafts \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Drafts can transform your insights from Hebbia into presentable documents—all formatted in your firm’s template, directly from the Home page. Simply point Hebbia to a reference document, and it will automatically generate a new version with the same structure, populated with your analysis.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"6xJlNhGsipt3FSEPz8euZr\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Slides from Chat and Matrix \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Generate slides directly from Chat or Matrix. Whether you need a single slide from your analysis or a complete presentation in your firm’s template, you can seamlessly turn research into client-ready outputs.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"4vg6TMZLeDxHnkkEpsCxhI\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"440sVg2o7R2Ny0LSyebtSe\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Financial Modeling Agents\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Hebbia now generates financial models that can be exported to Excel. With formulas and structure pre-built, you can populate forecasts, valuations, and comps in seconds.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"No browser excel knockoffs—just one click to import into the MS Office Suite. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"3jLMt6rZ3Mnu9wKWLdPi6\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Auto Model Selection and Faster Chat \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Hebbia automatically selects the best model for your workflow in Chat and Deeper Research. And, with recent enhancements to Chat, you can run complex analysis over vast amounts of data even faster.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"chi809JUhgrTqJBFOTqkU\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix Chat on GPT-5\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix Chat now runs on GPT-5, delivering greater accuracy and depth when building, editing, and analyzing matrices.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"3ANuMVFi4rq1q0emrCBu2O\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Consensus Estimates from S\u0026P Capital IQ \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Access aggregated, forward-looking broker estimates directly in S\u0026P Capital IQ. Metrics such as Revenue, EPS, EBITDA, Free Cash Flow, and more are available, each with high, low, mean, median, and standard deviation values for complete context.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"1OiPit4GyixnFBBwpzGDne\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Third Bridge Integration \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"You can now access Third Bridge content directly in Chat and Deep Research. Ground your analyses in expert interviews and sector intelligence—without leaving Hebbia—so every answer is backed by vetted, high-quality perspectives.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"7DbkICarbmgG4B1m7oboIJ\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Egnyte Integration \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Customers using Egnyte, an enterprise cloud storage solution, can now sync folders and make all their files available in Browse. Files are instantly usable in Chat, Research, and Matrix without extra steps.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"6r8w4PYBT8Q6rm723wSPf3\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Granular Source Control\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Control which public sources Hebbia pulls from by selecting earnings, filings, or investor presentations as standalone inputs. In Browse, you can also select subfolders within your private documents, filtering data down to just the files you want. The result is sharper searches and more relevant analyses.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"m2kLGzKjkcT435ikbTrTx\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Global Search in Browse\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Search and filter across all your public and private data in Browse simultaneously, so you can quickly find the files you need.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"7gFs3sXyvx00xAwYXunhgi\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[{\"sys\":{\"id\":\"6xJlNhGsipt3FSEPz8euZr\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6xJlNhGsipt3FSEPz8euZr/d9983cc57eaf491ee960545f35e3fdf0/10825_TheDisclosure_Inline_Drafts_Doc__3_.jpg\",\"description\":\"Drafts can transform your insights from Hebbia into presentable documents—all formatted in your firm’s template, directly from the Home page. \\n\"},{\"sys\":{\"id\":\"4vg6TMZLeDxHnkkEpsCxhI\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4vg6TMZLeDxHnkkEpsCxhI/b32327ecb342224285ba604266370d9b/10825_TheDisclosure_Inline_SlidesfromChat_V2__2_.jpg\",\"description\":\"Slides from Chat, now in Hebbia\"},{\"sys\":{\"id\":\"440sVg2o7R2Ny0LSyebtSe\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/440sVg2o7R2Ny0LSyebtSe/93cc8022ed5da23913161d524d419a88/101225_TheDisclosure_Inline_Drafts_NewAsset.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"3jLMt6rZ3Mnu9wKWLdPi6\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3jLMt6rZ3Mnu9wKWLdPi6/cc1e396f21131b866c28153247c12719/10825_TheDisclosure_Inline_FinancialmodelingAgents__2_.jpg\",\"description\":\"Hebbia now generates financial models that can be exported to Excel. With formulas and structure pre-built, you can populate forecasts, valuations, and comps in seconds.\"},{\"sys\":{\"id\":\"chi809JUhgrTqJBFOTqkU\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/chi809JUhgrTqJBFOTqkU/19c591d7acc007b708f82adfdbcb5184/10825_TheDisclosure_Inline_Chat__2_.jpg\",\"description\":\"Hebbia automatically selects the best model for your workflow in Chat and Deeper Research. And, with recent enhancements to Chat, you can run complex analysis over vast amounts of data even faster.\"},{\"sys\":{\"id\":\"3ANuMVFi4rq1q0emrCBu2O\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3ANuMVFi4rq1q0emrCBu2O/12797d17d6ed6eb988f5f853c4f86eb6/10825_TheDisclosure_Inline_MatrixChat__2_.jpg\",\"description\":\"Matrix Chat now runs on GPT-5, delivering greater accuracy and depth when building, editing, and analyzing matrices.\"},{\"sys\":{\"id\":\"1OiPit4GyixnFBBwpzGDne\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/1OiPit4GyixnFBBwpzGDne/798fe75721b69776e932e27d2570d169/10825_TheDisclosure_Inline_ConcensusEstimates__1_.jpg\",\"description\":\"Access aggregated, forward-looking broker estimates directly in S\u0026P Capital IQ. \"},{\"sys\":{\"id\":\"7DbkICarbmgG4B1m7oboIJ\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7DbkICarbmgG4B1m7oboIJ/37da17373927fb579df912f7540191da/10825_TheDisclosure_Inline_ThirdBridge__2_.jpg\",\"description\":\"You can now access Third Bridge content directly in Chat and Deep Research. Ground your analyses in expert interviews and sector intelligence—without leaving Hebbia—so every answer is backed by vetted, high-quality perspectives.\\n\"},{\"sys\":{\"id\":\"6r8w4PYBT8Q6rm723wSPf3\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6r8w4PYBT8Q6rm723wSPf3/178fa1d24e951afa9765d635d457e8f1/10825_TheDisclosure_Inline_Egnyte__3_.jpg\",\"description\":\"Customers using Egnyte, an enterprise cloud storage solution, can now sync folders and make all their files available in Browse. Files are instantly usable in Chat, Research, and Matrix without extra steps.\"},{\"sys\":{\"id\":\"m2kLGzKjkcT435ikbTrTx\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/m2kLGzKjkcT435ikbTrTx/059af2bf06a7a5411cd207d8c4459de3/10825_TheDisclosure_Inline_GranularSource__2_.jpg\",\"description\":\"Control which public sources Hebbia pulls from by selecting earnings, filings, or investor presentations as standalone inputs.\"},{\"sys\":{\"id\":\"7gFs3sXyvx00xAwYXunhgi\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7gFs3sXyvx00xAwYXunhgi/c0523ec0ee7e1e2a1268ed6ea371a5ca/10825_TheDisclosure_Inline_GlobalSearch_V2__2_.jpg\",\"description\":\"Search and filter across all your public and private data in Browse simultaneously, so you can quickly find the files you need.\\n\"}]}}}},{\"slug\":\"hebbia-crosses-1-billion-pages-processed\",\"title\":\"Hebbia Crosses 1 Billion Pages Processed\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-09-25T00:00:00.000-04:00\",\"category\":\"Company\",\"author\":\"Hebbia\",\"excerpt\":\"Today Hebbia crossed 1,000,000,000 pages processed—up from a mere 47 million pages just one year ago.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4xo5D4cLkAbQ73AeqFo7vU/ece240551cdb945b2345ccbedbf963e7/92325_Blog_1Billion_CoverImage_1200x600.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5WJmVGCwQstyrtfzbLvg5/2c865feab54c43ac5476f6bb6cb62b1b/92525_Blog_1Billion_Thumbnail_1063x1080-2.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5nJPTDR0gcVwMhTB9hXIqw/5093b4f114f68bb76380be68ffcdcbb3/92325_Blog_1Billion_BlogHeader_1600x534-2.png\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Markets generate more information each day than any team could ever process. Earnings calls, filings, research, contracts, regulations, and press releases add up to trillions of pages. Buried in that noise are the signals that move markets—signals you can only uncover with the right information.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"But no analyst team, no matter how large, could ever read enough to find them. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"That’s why scale matters.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Today Hebbia crossed \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"1,000,000,000 pages processed\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"—up from a mere 47 million pages just one year ago. At the average human reading speed, that’s the equivalent of \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"1.5 million days of reading\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"—compressed into seconds and surfaced as signal.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The exponential pace of AI adoption in finance shows no signs of slowing. As data volumes and analytical complexity surge, only platforms engineered for true scale—like Hebbia—are equipped to meet the demands of tomorrow’s financial markets. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A new class of AI use cases\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"AI is no longer only about efficiency.  Scale, especially in the financial markets, unlocks a completely new way of working with these tools. AI that can drive upside: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Weak signals\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" only emerge when you’ve seen the full corpus. Market-moving insights are often buried in footnotes, side comments, or obscure filings—patterns that only surface when you’ve read everything.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" requires breadth—knowing if a statement matters means comparing it to millions of others. To know if a single disclosure matters, you need to compare it against millions of similar statements across time, sectors, and geographies.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Rarity\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" becomes visible only at scale, the way physicists run billions of collisions to observe a single event. Hebbia’s \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://www.hebbia.com/blog/goodbye-rag-how-hebbia-solved-information-retrieval-for-llms\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Information Retrieval Engine\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\" (over all this scale) preserves full document integrity with precise source-linking across an unlimited amount of documents, letting you surface the single document, or single clause, that matters. \",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"AI at a small scale is an experiment. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"AI at billion-document scale is an \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"edge\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\".\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Built with Leading Firms on Wall Street\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Founded in 2020, Hebbia has become the platform of choice for the most discerning teams in finance—from investment banks, hedge funds, and private equity to Fortune 500 companies, consulting firms, and law firms—and is now expanding globally with customers across the UK and Europe. Building alongside these market leaders gives Hebbia an unmatched view into end-to-end workflows, allowing us to engineer the most powerful AI product in finance.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"With investments in workflow automation—from creating slide decks to building financial models—Hebbia is building a product deeply embedded in the workflows of finance professionals. Earlier this year, the platform also expanded with Deeper Research, Agents, and several new financial data integrations, giving users even more power and flexibility. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"These investments make it possible for more customers to tap into Hebbia and uncover insights that were previously out of reach.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Future of Finance \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Crossing 1 billion pages isn’t just a Hebbia milestone. It’s proof that financial institutions are using AI infrastructure at scale, and hungry for more compute. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Today, Hebbia powers the investment and banking ecosystem with the volume and velocity required to separate signal from noise.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This is only the beginning.\",\"marks\":[],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[]}}}},{\"slug\":\"how-private-credit-teams-use-hebbia\",\"title\":\"How Private Credit Teams Use Hebbia\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-09-22T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Charlie Pickell\",\"excerpt\":\"Hebbia helps private credit firms automate the heavy lift of screening, benchmarking, and precedent analysis so teams can focus on judgment, analysis, and negotiation.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3Hmq0SDTQhYFkA0Hh69A9Q/4bf4e34ff5ea9ac7b2519c9bc2f08861/9925_Blog_PrivateCredit_CoverImage_1200x600.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/9V23dSfCRoqDtbL378lv2/aa4026f6bfe047813634d0879b8e389c/9925_Blog_PrivateCredit_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/61ot6sEYGLXy98aG1IFqRa/604521baa91cc78e233b3a20ebb5a6d2/hebbia-tool-2025-09-19T20.49.45.240Z-1600x532_1.png\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Private credit teams evaluate thousands of opportunities with incomplete information and tight timelines. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Each new deal involves hundreds of pages of diligence materials, credit agreements, and financial statements, plus precedent knowledge hidden in past IC memos. The challenge isn’t in finding documents, but extracting the right terms, benchmarks, and comps fast, while maintaining defensibility in front of the investment committee, sponsor, and borrower.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Hebbia helps private credit firms automate the heavy lift of screening, benchmarking, and precedent analysis so teams can focus on judgment, analysis, and negotiation.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Here are four ways private credit teams are using Hebbia:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"ordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"IC memo libraries\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"New deal screening\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Origination\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Credit agreement analysis\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"1. IC Memo Deal Library\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Build a searchable repository of IC memos to benchmark deal terms, highlights, and risks vs precedent.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Past IC memos contain valuable analyses on credit quality of previously analyzed companies, in addition to key terms, risks, structures, etc. Leveraging these can be valuable for cross-referencing new opportunities.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Problem: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"These memos are scattered across folders, rarely standardized, and difficult to filter by criteria such as deal type, size, sponsor, or industry. Analysts rely on institutional memory, which creates inconsistency, slows benchmarking, and often prevents it altogether at the junior level.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"How Hebbia Helps: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Hebbia centralizes past IC memos into a queryable library. Using Matrix, credit teams can instantly filter by key attributes and surface the most relevant precedents. Analysts can issue queries like:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Show me pricing from previous deals \u003e$50m EBITDA with leverage above 6x”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Summarize key risks flagged in sponsor-backed healthcare deals in the last 24 months”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix outputs structured, filterable, source-linked results in clean tables or sentences, so analysts can compare precedent terms directly in memos or use them in live negotiations.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"2. New Deal Screening \u0026 Initial Short-Form Memo\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Generate a defensible first-pass memo from CIMs or decks in minutes instead of hours.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Every CIM or marketing deck requires a first-pass assessment to decide whether to pursue the deal. These short-form memos need to be both consistent and facts-focused.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Problem: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Drafting a first-pass memo using initial diligence materials can take up to 1–2 days. Analysts extract business fundamentals and key metrics from lengthy, often fluffy, decks, and seek answers to basic diligence items.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"How Hebbia Helps: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Hebbia generates a draft memo focusing only on the elements the analyst prescribes, cutting through the chaff and laying out a solid initial thesis on highlights and risks. Analysts can ask:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Draft a section on how this company makes money – explain it simply in layman’s terms”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“How is customer concentration, and how sticky are their key customers really?”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix produces a structured summary — company overview, main segments, recent performance, competitive positioning — each tied to the original source, that can be married with a cross-check vs precedent, comps, or the web. What once took days is now done in hours, with memos built on verifiable, defensible inputs. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"3. Origination\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Surface hidden opportunities by scanning filings, transcripts, and news for refinancing signals.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Finding opportunities entails surfacing lenders with rumored strategic alternatives, refinancing needs, liquidity issues, acquisitions, or other sponsor dynamics at play. These signals are buried across emails, news, and an unreadable amount of call transcripts.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Problem: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"The return-on-time invested into scouring for these deals is often low. Reading through hundreds of files to find one or two opportunities is hardly worth it. Thus, opportunities are often missed, and origination efforts depend heavily on memory and personal networks or relationships, which becomes increasingly challenging in a growing space. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"How Hebbia Helps: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"With Browse and Matrix, teams query across filings, transcripts, and thousands of emails to identify upcoming capital needs, and focus efforts down to those their firm has the most appetite for. Example queries include:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“List all borrowers mentioning 2026 debt maturities in earnings transcripts or filings”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Which sponsor portfolios have companies that discussed covenant relief in the past 2 quarters?”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix then surfaces the most relevant opportunities, with propensity to align to your firm’s strong suits, and points you where to devote your time. Origination teams build robust, living pipelines to grow their firm’s top of funnel.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"4. Credit Agreement Analysis\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Extract and benchmark covenant terms, baskets, and carve-outs across agreements in minutes.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Portfolio monitoring and deal structuring both require a deep understanding of credit terms. Knowing where protections are strong or weak is critical to negotiations, and ongoing portfolio health.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Problem: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Teams rely heavily on external counsel for reviews. Portfolio-wide benchmarking is slow and requires line-by-line reading of each agreement. Amendments and LME risks in a pinch force repeated re-reviews.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"How Hebbia Helps: \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"Matrix enables cross-document covenant comparisons at scale. Analysts can query:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Which Stonerock-backed deals had high Serta risk and why?”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"“Compare standard EBITDA add-back caps for the last 10 deals we’ve reviewed and compare to this one”\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Results are delivered in structured, source-cited tables that highlight where to focus in the docs. This allows private credit teams to reduce reliance on counsel for first-pass reviews and approach negotiations armed with precedent.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Why Private Credit Teams Choose Hebbia\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Private credit demands speed, accuracy, and defensibility. Hebbia delivers all the above by combining:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Matrix\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" for structured, source-cited benchmarking and relative analysis.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Browse\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" for precise source finding and organization across vast data sets.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Iterative Source Decomposition (ISD)\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" to preserve full context and structure, ensuring outputs are defensible in ICs and negotiations.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Hebbia doesn’t replace judgment but it automates the extraction and structuring of deal content, so private credit teams can focus on the investment call itself.\",\"marks\":[],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[]}}}},{\"slug\":\"who-evaluates-the-evaluator-reaching-autonomous-consensus-on-agentic-outputs\",\"title\":\"Who Evaluates the Evaluator: Reaching Autonomous Consensus on Agentic Outputs\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-09-19T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Jake Skinner, Davis Li, Adithya Ramanathan \",\"excerpt\":null,\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6olndqzlHQpjeCkl8SFrn9/72684d7187ef0ee491072f63680a2a69/102225_Blog_LLM__WhoEvaluates_CoverImage_1200x600__1_.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2LDeN00ngm0z15dTC9GLwS/6403d91fd10e60bf6377a5f86c977b23/102225_Blog_LLM__WhoEvaluates_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7MA4jQWIQPuMGJ4fTGHinJ/e8888dc5ed83267f720a319cac68dd61/102225_Blog_LLM__WhoEvaluates_BlogHeader_1600x534__1_.png\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Abstract (TLDR):\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"$18\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Introduction - Why “Good Enough” Isn’t Enough\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The distinction between evaluation and testing is often lost—just ask any teacher or school administrator. Testing tends to focus on measuring specific skills or knowledge, usually with a right-or-wrong answer key in hand. Evaluation, on the other hand, is the awkward cousin that asks a more philosophical question—is the answer \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"actually\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" good? Is it relevant, insightful, or readable. That distinction matters the moment you stop demoing a single prompt in a Jupyter notebook and start orchestrating a chain of half a dozen agents against 3000-token earnings transcripts. One stray temperature tweak can lift \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://en.wikipedia.org/wiki/ROUGE_(metric)\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"ROUGE-L\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\" while simultaneously hallucinating a brand-new division of your company or a legal precedent that doesn’t actually exist. Welcome to the deep end.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"At Hebbia, we run hundreds of thousands of LLM calls each day—often in parallel, always under latency constraints. Our prompt-engineering process looks less like quiet academic research and more like a Formula 1 pit stop: wrench, refuel, deploy, pray. Except the car is built from stochastic fog, the track layout changes every lap, and the telemetry lights are occasionally hallucinated. As AI engineers, when we bump verbosity by 20%, conciseness can crater; when we clamp hallucination rate, suddenly factual coverage could evaporate. Very quickly, the notion of “better” devolves into pure vibes—and nobody wants to explain to security why \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"vibes\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" crashed production.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Given how long the AI race has been underway (barreling full speed toward AGI, consciousness… or just better autocomplete), you’d think LLM evaluation would be a solved problem. Turns out, it’s not. The open-source evaluation landscape is still a patchwork of clever scripts, one-off metrics, and statistical shortcuts that would make a first-year biostatistician cry. We need a framework that treats qualitative judgments with the same mathematical respect we give to A/B tests: hard p-values, bootstrap confidence intervals, and clear “ship or skip” decisions that even product managers can trust. In short, \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"vibes need standard errors\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\". This paper lays out how we got there, what we learned from benchmarking the usual LLM suspects, and how you can replicate—and extend—the approach without reinventing the wheel.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Standing on the Shoulders of Giants \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Before we built our own evaluation framework, we reviewed several foundational efforts. If you're serious about LLM evaluation, these are required reading:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Link: \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://arxiv.org/abs/2303.16634\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Paper Here\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Authors: Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, Chenguang Zhu\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"One-liner: Pioneered the use of logits to create a continuous distribution of evaluation scoring.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"GPTScore: Evaluate as You Desire\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Link: \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://arxiv.org/abs/2302.04166\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Paper Here\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Authors: Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, Pengfei Liu\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"One-liner: Created a robust framework for generating and applying evaluation criteria across tasks and models. \",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"BooookScore: A systematic Exploration of Book-length Summarization in the Era of LLMs\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Link: \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://arxiv.org/abs/2310.00785\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Paper Here\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Authors: Yapei Chang, Kyle Lo, Tanya Goyal, Mohit Iyyer\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"One-liner: Took on the Herculean task of long-form summarization and invented a clever head-to-head scoring routine. Also gets points for best paper title in this list. \",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Link: \",\"marks\":[],\"data\":{}},{\"nodeType\":\"hyperlink\",\"data\":{\"uri\":\"https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf\"},\"content\":[{\"nodeType\":\"text\",\"value\":\"Paper Here\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Authors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, et al.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"One-liner: Asked the original question—can an LLM judge another LLM? Spoiler alert: yes, and it turns out GPT-4 agrees with humans more than humans agree with humans. One of the most comprehensive and scaled studies of LLM-based judgment to date.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Hebbia’s Qualitative LLM Evaluation Framework\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Our approach to LLM evaluation borrows heavily from G-Eval and GPTScore, with some long-context seasoning from \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"BooookScore\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\". We’ve tried to pull together the best elements of these frameworks and build something that feels more in line with how traditional statistical hypothesis testing works—because who doesn’t love bootstrapped p-values?\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Enough talk—let’s get in the ring. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Suppose we want to optimize our prompts based on a set of arbitrary-but-reasonable qualitative criteria. In the red corner, we have Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HO\",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" (our control, the null hypothesis). In the blue corner, Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HA \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" (our new and possibly improved agent).\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Here’s the simplified version of the process:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"ordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Give a common set of source documents to Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HA \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" and Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HO \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Submit a series of questions or tasks to each agent and store their responses. For more robust results, submit each question \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"J\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" times with varying temperature settings.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Construct an evaluation agent (Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"EVAL\",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\") to independently score the responses. Each criterion-question pairing is a separate LLM call, and each response is rated on a Likert scale from 1 to 5. This separation is key: it ensures that each score is independent and discrete, untouched by the bias of scoring multiple things at once or comparative bias by doing head-to-head evaluations.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For each Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"EVAL \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"response, capture and store the log probabilities for its score token and exponentiate these into linear probabilities for easier interpretability. \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Use the array of linear probabilities to normalize their respective tokens and then sum them to produce a weighted-average score for a specific criterion-question pairing.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Once this process is complete for all criteria, queries, and for Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HA \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"and Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HO\",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\", store the results; if there are other surface areas (aka other prompt families), then run them.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Repeat this entire process N times. LLMs are inherently noisy and stochastic, and running this just once is akin to flipping a coin and calling it science. By repeating, you get a sample distribution over which you can actually do hypothesis testing and avoid Type I errors—aka false positives, aka “we thought it was better, but it was just lucky.”\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"After N runs are complete, align and pool the data across disparate runs and store as an experimental set.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A visual representation of this algorithm is as follows:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"4DXDB6PzHhpxHw91So8jzC\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Fun with Numbers: Evaluation Criteria and Statistical Testing\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For abstractive evaluation criteria, we devised a shortlist assembled from across our literature review. Each criterion includes three positive and three negative examples to anchor what “good” and “bad” looks like. This isn’t just window dressing—we found that giving LLM  based scorers concrete examples dramatically improves consistency and sharpens distinctions between vague concepts like “clarity” and “factual grounding.” We also annotate specific criteria with custom notes for the evaluator model that call out common pitfalls we’ve run into while iterating on this framework—things like scoring verbosity too generously, or judging markdown-based responses too harshly.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Once the results are in, the real question becomes: when is a difference in scores \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"actually\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" meaningful?\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"To test this, we explored three paths for significance testing between sample means:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"ordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Isolated by question (cross-criteria)\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" – Does one prompt outperform another across \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"all criteria\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" on a specific question?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Isolated by criterion (cross-question)\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" – Does one prompt perform better on a specific \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"criterion\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" across \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"many questions\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Isolated by both question and criterion\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" – Does one prompt do better on \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"this criterion\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" on \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"this specific question\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"?\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For each path, we run a two-sided permutation test with α = 0.05 over 10,000 iterations. This lets us capture not only improvements but also regressions (things can always get worse). If we had a much larger dataset, we’d also consider non-parametric alternatives like the Mann-Whitney U test—just make sure it’s two-sided to catch both directions of change.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Bringing It All Together: Applications \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Given that Hebbia is model and platform agnostic, we offer a wide variety of models from Anthropic (Claude) and OpenAI (the GPT family). We also cater to Gemini models, but they were not tested in this experiment. Therefore, one of the questions we most often get is which models to use or not use for a given task. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"In our setup, we take a one-vs-all and one-vs-one approach. For testing a specific agent relative to all peers, we state that Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HO  \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"is the collection of all criteria scores from agents powered by our non-target model with Agent\",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"HA \",\"marks\":[{\"type\":\"subscript\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"representing the evaluator scores for our target model. We then design a battery of extractive and abstractive questions that require synthesis, critical thinking, and different forms of needle-in-the-haystack-like extraction.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"With this experimental design in mind, the question we want to answer is, “Does providing an agent with model X, in comparison to model Y,  improve or degrade the quality of answers as defined by our criteria?” Stated more scientifically across the aforementioned criteria, we can represent the hypothesis testing procedure as:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Let\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"e3nLcBfQTHVMR8gdwPyfe\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Then the full test procedure becomes a set of simultaneous hypothesis tests, one for each level as defined by our aforementioned testing paths, with Type I errors controlled by our permutation-based p-values. Who knew vibes could be so scientific?\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"With the entire procedure being represented as:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"407zGDsKWs5bHQJsPwhzum\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"And the null hypothesis as: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"14fmwrfZm922gifXEcqhWT\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Since Hebbia works with many large financial institutions, we decided to focus our evaluation across a number of tasks that our clients tackle most often. We split the tasks across abstractive and extraction tasks—for extractive tasks we evaluated not only whether the agent was able to get the correct answer but also whether it properly followed formatting instructions for the returned answer. Abstractive tasks required a bit more nuance; for these questions, we evaluated the response across the following criteria: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Plausibility\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Relevance \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Specificity and Detail\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Insightfulness/Analytical Sharpness\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Logical Coherence\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Conciseness\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A sample of the types of questions we asked are as follows:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Extractive Samples\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What was the company's total revenue for the quarter?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What was the company’s digital sales as a percentage of total revenue?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What is the total number of stores open in the Middle East?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What is the company’s guidance for revenue in the next quarter?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What are the LTOs this quarter?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What are the new store targets (number and date)? \",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Abstractive Samples \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Summarize the primary factors that impacted sales performance this quarter.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Summarize management's commentary on industry trends.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Summarize management’s commentary on macroeconomic consumer spending trends.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Why is management confident in their growth targets?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What were analysts concerned about?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"What did management struggle to answer?\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Return verbatim all of the analyst questions asked by John Smith (name redacted).\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Our hyperparameters were as follows:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"J\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" = 3\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"N \",\"marks\":[{\"type\":\"italic\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"= 50\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Model Type: varied\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Model Temperature: 0.1-1.0 (model dependent variations)\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Diving into the Data\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-3\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Abstractive Results\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Abstractive Criteria Scores by Question Category\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"5zyh9muFU2YemGZIudmN7\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The aggregated raw score results reveal some fascinating patterns! Across our two broad meta-categories of abstractive tasks—Summarization and Reasoning—we see:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"That o3 and GPT-5 consistently emerge as the top performers with meaningful distance between them and their closest peers\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"We observe that the Anthropic models (4-sonnet and 4-opus) perform better with reasoning than summarization–suggesting architectural or training differences that favor analytical tasks over distillation tasks \",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Note that for Reasoning, we removed the mini-models since they consistently performed below the rest of the pack—a clear indication that model size matters for complex reasoning tasks.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Abstractive Criteria Scores by Question Subcategory\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"1nMD1a5LpDMh8aH8Xsoz3J\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Looking deeper into the individual criteria scores:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"GPT-5’s dominance \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"is particularly pronounced in Insightfulness/Analytical Sharpness, suggesting its training has optimized for deep analytical capabilities. More on this in the extractive section below.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"GPT-4.1\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" shows remarkably consistent performance across criteria, never falling below 4.0, making it a reliable \\\"generalist\\\" choice.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Extractive Results\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Extractive Criteria Scores by Question Category\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"7MSFFGQbzWWHdGzvZUq7pc\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The extractive results paint a different picture entirely. While o3 and GPT-5 dominated in Reasoning and Summarization categories, we see that they struggle at both term extraction and verbatim extraction compared to their peers. This is a critical finding—GPT-5 and o3's strength in understanding and synthesis comes at the cost of precision in literal reproduction.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Key observations:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"OpenAI's 4.1 model\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" emerges as the extraction champion, particularly excelling at verbatim extraction with scores approaching 5.0.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The mini-models\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" show surprising competence with data extraction, suggesting that structured extraction tasks may not require the computational overhead of larger models.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Claude models\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" maintain middle-of-the-pack performance, neither excelling nor failing dramatically.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"GPT-5 is Chatty\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"—it is underwhelming when asked to extract specific information and tends to break formatting instructions due to its verbosity. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Head-to-Head Results and Statistical Significance \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Next, we get down to the brass tacks of head-to-head battles and the assessment of statistical significance. As a reminder, we're using a two-sided permutation test with 10,000 iterations and an alpha at 0.05. To produce the following results, we run each model's results against every single one of its peers independently—we focus specifically on cross-category and cross-criterion performance.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"24eQilnK1c8yo3kV5HqxlF\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"2tB9uAjR8crne04pomblxy\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For summarization:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"GPT-5  achieves statistical significance against all models except itself (obviously) and o3.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"4-opus consistently loses to newer GPT models, suggesting their rapid advancement in summarization capabilities.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Ties between closely matched models (like 3.5 and 3.7) indicate marginal improvements between versions.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For reasoning:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The dominance hierarchy is clearer: GPT 5 \u003e= o3 \u003e 4.1 \u003e 4-sonnet \u003e others.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A higher percentage of ties appear in this category, suggesting reasoning capabilities have plateaued somewhat across model families.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Note that we removed o4 and 03-mini from this specific category\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"4r7iXDSnveOXmy9vgCy5ZY\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"3KwyYN3V036uJ5pLCoboK0\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"4VYg8JuqIdvV5zHWl0iXqE\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"01fowXC6UmWnGZqFilvs0k\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"embedded-asset-block\",\"data\":{\"target\":{\"sys\":{\"id\":\"4hQGXPvu0zrp9W5epihY43\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"At the criterion level, the specific results look as follows:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For specific criteria:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Relevance:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Most models achieve statistical ties, suggesting this is a \\\"solved\\\" problem for modern LLMs, though it’s interesting GPT-4.1 and 5 tie in this area.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Plausibility:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Near-universal ties indicate all tested models have achieved human-level plausibility.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Logical Coherence:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Clear stratification emerges, with GPT-5 and o3 dominating, followed by 4.1, then a cluster of Claude models.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Insightfulness/Analytical Sharpness:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" The most discriminating criterion, with GPT-5 taking the lead over o3 and achieving significance against all competitors.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Multiple Comparisons and False Discovery Rate\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"An astute reader might notice we're conducting hundreds of hypothesis tests (models × criteria × questions). This raises the specter of multiple comparisons problems. While we don't apply Bonferroni correction (which we felt would be overly conservative), our use of permutation testing with 10,000 iterations provides robust Type I error control at the individual test level.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For future work, we're exploring False Discovery Rate (FDR) control methods like Benjamini-Hochberg, which would allow us to make stronger claims about the proportion of true discoveries among our significant results. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Key Insights and Takeaways\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"ordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Model Selection Is Task-Dependent:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" o3 excels at synthesis and reasoning but struggles with precise extraction. Choose your model based on your primary use case.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The Anthropic Paradox:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Claude models show a peculiar pattern—excellent reasoning capabilities coupled with verbose outputs. This suggests potential for prompt engineering to constrain response length while maintaining quality.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Mini-Models Surprise:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" For well-defined verbatim-extractive tasks, mini-models can compete with their larger siblings at a fraction of the computational cost.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Statistical Significance ≠ Practical Significance:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Many statistically significant differences translate to score differentials of 5-10 points. While this may seem small, marginal improvements have significant implications for high-scale use cases. While it wasn’t specifically tested in this trial run, the performance in analytical insightfulness could be an interesting proxy for tool-calling use cases.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The results didn’t just feel right, they also matched expert opinion. We validated our automated scores against human-labeled examples from former hedge fund analysts and saw strong alignment. What a top-performing analyst would rate as insightful, our framework rated as insightful, too.\\n\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Technical Considerations and Limitations\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-3\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Evaluation Metrics and Biases, Potential Gotchas\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"While our framework addresses many limitations of existing approaches, several challenges remain:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"ordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"LLM Evaluator Bias:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Using LLMs to evaluate LLMs introduces potential bias. Models may favor outputs similar to their own style. \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Criteria Interdependence:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Although we score each criterion independently, they're not truly orthogonal. High logical coherence often correlates with high plausibility, for instance.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Context Window Effects:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Longer documents may disadvantage models with smaller context windows, even if their actual understanding is comparable.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Prompt Sensitivity:\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" Small variations in evaluation prompts can lead to different scores. We've standardized our prompts through extensive iteration, but this remains a source of potential variance.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Statistical Power and Sample Size\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"With J=3 and N=50, we achieve reasonable statistical power for detecting large effects (Cohen's d \u003e 0.8). However, smaller effects may go undetected. Power analysis suggests that for detecting medium effects (d ≈ 0.5) with 80% power, we'd need approximately N=100 bootstrap iterations.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The trade-off is computational cost—each additional bootstrap iteration requires 3 × (number of questions) × (number of criteria) × (number of models) LLM calls. At current API pricing, this becomes expensive quickly, and while we take these steps in production we felt that for this evaluation the that approach would have been excessive.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Conclusion\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"At Hebbia, we believe that LLMs and the agents they power are central to the future of enterprise workflows, and thus evaluation must evolve alongside them—not just in scale, but in sophistication. In this paper, we introduced Hebbia's framework for consensus-based LLM evaluation with the aim of blending theoretical rigor with statistical and empirical validation.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"By synthesizing advances from G-Eval, GPTScore, and BooookScore, and reinforcing them with permutation-based hypothesis testing, we constructed a system that can autonomously evaluate qualitative performance with statistical fidelity. Add in the ability for our users and our internal teams at Hebbia to define criteria ad hoc based on the objectives of a given agentic system, and you have a flexible and adaptable framework that scales with your needs.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Looking ahead, we aim to extend beyond simple model-to-model comparison to encompass system-level evaluations, planning agent benchmarking, and fine-grained debugging of agent behavior. As agentic systems become more complex—incorporating tool use, multistep reasoning, and dynamic context management—so too must the tools we use to measure them.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Precision matters—especially when \\\"good enough\\\" isn't enough. In the high-stakes world of financial analysis, legal discovery, and enterprise intelligence, the difference between 95% and 99% accuracy can be millions of dollars. Our evaluation framework helps ensure we're always moving in the right direction, one statistically significant improvement at a time.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"hr\",\"data\":{},\"content\":[]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"The authors would like to thank the Hebbia engineering team for their patience during the hundreds of thousands of API calls required for this research, and the finance team for not looking too closely at the OpenAI, Google, and Anthropic invoices.\",\"marks\":[{\"type\":\"italic\"}],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[{\"sys\":{\"id\":\"4DXDB6PzHhpxHw91So8jzC\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4DXDB6PzHhpxHw91So8jzC/57d12a76be5516f0b25093e8e358d455/9925_Blog_LLM_Graph_1600x700.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"e3nLcBfQTHVMR8gdwPyfe\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/e3nLcBfQTHVMR8gdwPyfe/c6d9b664fb8978afb50c1e550ceff1a0/Screenshot_2025-09-22_at_1.57.59â__PM.png\",\"description\":\"\"},{\"sys\":{\"id\":\"407zGDsKWs5bHQJsPwhzum\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/407zGDsKWs5bHQJsPwhzum/8632eca44e23c358a7ec9f40c2efd7f1/Screenshot_2025-09-22_at_2.00.15â__PM.png\",\"description\":\"\"},{\"sys\":{\"id\":\"14fmwrfZm922gifXEcqhWT\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/14fmwrfZm922gifXEcqhWT/08fae0b01e767ba2767d52907660325d/Screenshot_2025-09-22_at_2.07.57â__PM.png\",\"description\":\"\"},{\"sys\":{\"id\":\"5zyh9muFU2YemGZIudmN7\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5zyh9muFU2YemGZIudmN7/e70bc0657c782b6e550f00b6e9e6e296/1027_Blog_LLMEvaluates_Graph_1600x700_abstractive_category_group_model_barplots_V1__1_.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"1nMD1a5LpDMh8aH8Xsoz3J\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/1nMD1a5LpDMh8aH8Xsoz3J/07d0e71afdf9b0312e31090a1ebac142/1027_Blog_LLMEvaluates_Graph_1600x700_abstractive_category_criterion_name_barplots_First_V1__1_.jpg\",\"description\":\"Abstractive Criteria Scores by Question Subcategory\"},{\"sys\":{\"id\":\"7MSFFGQbzWWHdGzvZUq7pc\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7MSFFGQbzWWHdGzvZUq7pc/d1473924ff8b24e5ac172bacbfa273f5/1027_Blog_LLMEvaluates_Graph_1600x700_extractive_category_group_model_barplots_V1__1_.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"24eQilnK1c8yo3kV5HqxlF\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/24eQilnK1c8yo3kV5HqxlF/cd48928c30d712b9fd81e72cc8c2010c/1027_Blog_LLMEvaluates_Graph_1600x700_Summarization_V1__1_.jpg\",\"description\":\"evaluating llms query: summarization\"},{\"sys\":{\"id\":\"2tB9uAjR8crne04pomblxy\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2tB9uAjR8crne04pomblxy/328561e40cec449b67f6db20887bfaff/1027_Blog_LLMEvaluates_Graph_1600x700_Reasoning_V1__1_.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"4r7iXDSnveOXmy9vgCy5ZY\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4r7iXDSnveOXmy9vgCy5ZY/b49206fe93c9852ec2ed019b6dd92ad6/1027_Blog_LLMEvaluates_Graph_1600x700_abstractive_category_criterion_name_barplots_Second_V1__1_.jpg\",\"description\":\"winner matrix criterion name Insightfulness Analytical Sharpness\"},{\"sys\":{\"id\":\"3KwyYN3V036uJ5pLCoboK0\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3KwyYN3V036uJ5pLCoboK0/c9ca8a634478feca5f0b1c121a48d230/1027_Blog_LLMEvaluates_Graph_1600x700_winner_matrix_criterion_name_Logical_Coherence_V1__1_.jpg\",\"description\":\"winner matrix criterion name Logical Coherence\"},{\"sys\":{\"id\":\"4VYg8JuqIdvV5zHWl0iXqE\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4VYg8JuqIdvV5zHWl0iXqE/e4e3164fe37a86555e8acdbefcd5ff61/1027_Blog_LLMEvaluates_Graph_1600x700_Summarization_V1-1__1_.jpg\",\"description\":\"winner matrix criterion name Plausibility\"},{\"sys\":{\"id\":\"01fowXC6UmWnGZqFilvs0k\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/01fowXC6UmWnGZqFilvs0k/c6f02500b81f404276c439475b7dfc05/1027_Blog_LLMEvaluates_Graph_1600x700_Relevance_V1__1_.jpg\",\"description\":\"winner matrix criterion name Relevance\"},{\"sys\":{\"id\":\"4hQGXPvu0zrp9W5epihY43\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4hQGXPvu0zrp9W5epihY43/f15050e1ba2a1716fec0ad82acf62aa8/1027_Blog_LLMEvaluates_Graph_1600x700_Specificity_and_Detail_V1__1_.jpg\",\"description\":\"winner matrix criterion name Specificity and Detail\"}]}}}},{\"slug\":\"which-model-will-give-me-the-edge\",\"title\":\"Introducing Hebbia's Financial AI Benchmark\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-09-12T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Davis Li, Jake Skinner\",\"excerpt\":\"Hebbia’s Financial Services Benchmark tests leading LLMs on 600+ workflows spanning investment banking, private equity, credit, and public equities.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3pg8ogiwteW7A7Ji0jOV61/7e36517eb92fd443f65524d5f1aebce2/102225_Blog_LLM__WhoEvaluates_CoverImage_1200x600__1_.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2p4pibDPVtUPm28l5GlrRr/551b56f499d94245d8aa3f92804225cd/9925_Blog_LLM_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/ruSyBo7fPJ6oTrg73j540/bc1b8ad0e129427bd3ef087d6768101e/91725_Blog_LLM_BlogHeader_1600x534.png\"},\"content\":{\"json\":{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"As LLM innovation accelerates, finance professionals require a multi-model approach to uncover alpha. However, identifying the optimal model for specific needs remains a significant challenge. At Hebbia, we have spent years deeply understanding our customers’ diverse workflows—both typical and edge cases—and applying AI in ways that are both effective and realistic. Choosing the right LLM is central to this process.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We built the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Financial Services Benchmark\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" to identify the best models for workflows relevant to our customers in investment banking, private equity, credit, and public equities. Because our customers are highly discerning when it comes to numbers (they are, after all, in finance), we’ve made our \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://assets.ctfassets.net/bn476u6z5acg/34yWKS2ROc7FF0kfCbnhZu/058d685a2b87ea7e3663a7c91fb31843/Hebbia_Who_Evaluates_the_Evaluator__Reaching_Autonomous_Consensus_on_Agentic_Outputs.pdf\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"statistical methodology\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" fully transparent to the public.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Here are the key takeaways from our inaugural evaluation: \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"For extraction tasks, such as pulling out exact numbers, terms, or quotes, Claude 4 Opus and GPT-4.1 performed best\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\", accurately capturing specific details without errors or unnecessary information.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"For summarizing and reasoning, go with OpenAI’s o3 or GPT-5 models\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". o3 and GPT-5  consistently deliver the most insightful responses—surfacing deeper implications and strategic perspectives beyond restating facts. GPT-5 shot to the top of the leaderboard in summarization and reasoning, but its tendency to give overly detailed answers hurts precision on extractive tasks.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"With LLMs, you don't always get what you pay for. \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"Our evaluation found that premium models often perform similarly to less expensive options. For many tasks, GPT-4.1 matched the performance of top-tier models at a fraction of the price.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The LLM landscape is evolving rapidly, with models becoming increasingly specialized. Anthropic’s Claude, for example, recently entered the top five for financial workflows in our evaluation, demonstrating how quickly rankings can shift. The best strategy to ensure you're always adopting a multi-model approach so your business can evolve as quickly as the models themselves.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"No one-size fits all\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We put leading models to the test, including OpenAI’s GPT 5, o3, and GPT-4.1, Anthropic’s Claude 4 series, Grok 4, and Google’s Gemini. Our results show that no single model excels at every task. Most models now handle basic accuracy and relevance well, but the real difference comes from how insightful and clear their answers are. Using a mix of models helps ensure you get the best results for each type of task. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4AqKvRsZoCsoXHBELUlaBh\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\\n Each model was evaluated on more than 600 real-world finance questions, organized into three main categories:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"1. Extraction\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"These questions ask the model to find and report specific facts or details from documents. For example, “What was the company’s total revenue this quarter?”, “What were the promotions or limited time offerings this quarter” or “List all analyst questions asked by John Smith.” The goal is to measure how accurately the model can pull out exact numbers, terms, or quotes. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"2. Summarization\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In this category, the model is asked to condense information and highlight the main points. Prompts include, “Summarize management’s perspective on macroeconomic conditions,” or “Briefly describe the main factors affecting quarterly sales.” This tests the model’s ability to capture the essence of complex information.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"3. Reasoning\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"These tasks require the model to analyze information and provide deeper insights. For example, “What were analysts most concerned about, and why is this important?” or “Identify and explain any questions management struggled to answer clearly.” Here, we look for the model’s ability to interpret, explain, and connect ideas.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"GPT-4.1 and Claude 4 Opus are the most reliable for extraction, consistently pulling accurate details without unnecessary information. For summarization and reasoning, o3 and GPT 5 stands out by not just summarizing, but also explaining why the information matters and adding valuable context.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With LLMs, you don't always get what you pay for\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Many finance teams gravitate toward the newest and most expensive language models, expecting them to deliver the best results. However, our benchmark shows that price and hype do not always translate to better performance. In practice, some premium models only slightly outperform, or even underperform, their predecessors on key finance tasks.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3VWh55v6sTvZliJguMDJbn\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"For example, Claude 4 models quickly entered our top five upon release, but further analysis shows their outputs are often similar to those of more affordable alternatives. Established models like GPT-4.1 continue to excel in critical extraction tasks that are essential for accurate financial analysis. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Even models that once led the field can quickly fall behind. OpenAI’s o1, previously the top reasoning model, is now surpassed by o3, which offers sharper insights at a better price. Teams still using o1 are paying more for outdated technology and missing out on improved performance. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Our evaluation makes it clear: the best approach is to match model selection directly to task performance. A well-tested, multi-model strategy ensures you get the best value and results for your organization. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Conclusion\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The rapid evolution of LLMs presents both opportunity and complexity for financial services. Our evaluation makes it clear: there is no single “best” model for every workflow and price does not always correlate with performance. OpenAI’s o3 and GPT 5 excel at delivering insightful, strategic analysis, while GPT-4.1 and Claude 4 Opus lead in precise data extraction. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"As the LLM landscape continues to shift, the smartest strategy is to remain agile and data-driven, leveraging a multi-model approach tailored to your organization’s unique needs. With the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Financial Services Benchmark\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\", finance teams can confidently select the right models for each task, maximize performance, and stay ahead in a rapidly changing market.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The future of AI in finance is about making informed, evidence-based choices that drive real value. With Hebbia, you’re equipped to do just that.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[{\"sys\":{\"id\":\"4AqKvRsZoCsoXHBELUlaBh\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4AqKvRsZoCsoXHBELUlaBh/a846ec0311be0cb628162e2ccf48336e/Test_4.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"3VWh55v6sTvZliJguMDJbn\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3VWh55v6sTvZliJguMDJbn/841362c39526e7e1164c92325160a65d/9925_Blog_LLM_Chart_1600x700.jpg\",\"description\":\"\"}]}}}},{\"slug\":\"the-disclosure-august-2025\",\"title\":\"The Disclosure: August 2025\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-09-03T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Hebbia Team\",\"excerpt\":\"This month’s platform improvements cut friction, speed up analysis, and unlock new ways to move deals forward.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5vHc8Vw5NOlk8KLHNR9fYG/5e4ba3708b5ab664f061509b413d1ef3/9925_Blog_Disclosure_CoverImage_1600x700.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3vyRzMeA0NIhIqpjnYvClc/9399283a875a8ca843a181eb5523f8d9/825_Blog_TheDisclosure_Aug_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/723hUgmCsXaDBIMEdDgy5A/b25975cd492918029721384938de4538/9925_Blog_Disclosure_CoverImage_1600x535.png\"},\"content\":{\"json\":{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Your workflows just got an upgrade. This month’s platform improvements cut friction, speed up analysis, and unlock new ways to collaborate across your firm and move deals forward. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"To keep you on top of all the great products and features the Hebbia team is shipping at lightning speed, we're excited to share our August edition of \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"The Disclosure\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\", our inaugural monthly recap. These updates aren’t just features—they’re your edge.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Company Matrix \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Strip profiles, deal origination, and portfolio analysis will never be the same. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Matrix is not only for analyzing documents at scale but also for comparing public and private companies across multiple dimensions. Spin up strip profiles and comps tables in minutes, with fields auto-populated from your documents and public data sources.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2QbppwhXuklEZwVHi6jefM\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Follow-Up Columns\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Drill deeper into any document, any analysis, and any investment. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Chain multi-step analysis in Matrix so prompts across your documents and the web can build on prior analysis results. Follow-up columns in Hebbia enable you to control the model’s logic across steps for consistent, auditable outputs and streamlined analysis.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4KSPgTfTZVP4mkt83v1B4d\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Couple follow up columns with company grid to create agents on a per company level—even if you’re using them for on cycle PE-recruiting: \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6MUiUleuAKSCRa4WXaKq4W\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Purpose-Built Agents \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Your prompts and processes are your firm's IP. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"You can now create your own Agents to share repeatable workflows with your team in an organization library. Build one-click Agents to jump start Meeting Prep, generate IC Memos, or analyze Credit Agreements, the way your firm operates.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"2O9vWhtNEAybTDkOjE8GTa\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3J9kK7CulyssOE1zIuRYZR\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Document to Agent \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Upload a reference doc or describe your workflow, and Hebbia decomposes it into a reusable agent schema. Every new doc you add to this Matrix is automatically analyzed for the same fields—financials, KPIs, covenants and headroom, maturity schedules, etc.—no prompting required. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"6FFmhwUJaxvOdOrMh8K1rD\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4IaGdVVTeFDfmBwN1PTZzP\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Professional PDF Exports\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Export content created in Hebbia into polished PDFs with clean formatting, cover letters, structured sections, preserved citations, and your firm’s logo. Generate memos, one-pagers, and research packs in minutes—ready to share with your team and MDs.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"7DVmwUnHJ63HPdg2015Hjr\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Conference Presentations\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We’ve added conference presentations to the Sector Insights library, alongside S\u0026P‑verified market news and conference transcripts. Ground your searches in vetted, up‑to‑date industry sources—skip the noise of unreliable web content.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"4rcARju8coftyjD3OwxpQR\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Web Page Crawler \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Crawl entire sites—portfolio company websites, IR hubs, and regulatory/research portals—and bulk-ingest docs into Hebbia with source URLs preserved. Don’t just search the web; index it on the fly so everything is instantly searchable and ready for downstream analysis.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5lY8UAYIqitY7osYB81Fsr\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Auto-Extract Tables \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Hebbia automatically detects and extracts all quantitative tables from every file for instant Excel export. Automatically pull financials from SEC filings, KPIs from investor decks, debt maturity schedules and cap tables from notes and press releases, precedent deal tables, and more. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"1MP2Irsn33jJXUOFD3Oj7j\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"56z8f0D7T11DTfbDdiqxuf\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[{\"sys\":{\"id\":\"2QbppwhXuklEZwVHi6jefM\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2QbppwhXuklEZwVHi6jefM/6181803eb335fe863f5288ed06a9074b/Product_Mock__9_.jpg\",\"description\":\"hebbia matrix company rows\"},{\"sys\":{\"id\":\"4KSPgTfTZVP4mkt83v1B4d\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4KSPgTfTZVP4mkt83v1B4d/88cb7634061421281026ecb44e3e9d63/follow_up_columns.png\",\"description\":\"Follow-up columns in Hebbia enable you to control the model’s logic across steps for consistent, auditable outputs and streamlined analysis.\\n\"},{\"sys\":{\"id\":\"6MUiUleuAKSCRa4WXaKq4W\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6MUiUleuAKSCRa4WXaKq4W/a63ab3c5f41109fd6fb0c3fb6586af81/company_matrix.gif\",\"description\":\"With Hebbia's Matrix you can spin up strip profiles and comps tables in minutes, with fields auto-populated from your documents and public data sources.\\n\"},{\"sys\":{\"id\":\"2O9vWhtNEAybTDkOjE8GTa\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/2O9vWhtNEAybTDkOjE8GTa/96363ff47740b493b7a163f7fd35f887/purpose_built_agents.gif\",\"description\":\"You can now create your own Agents to share repeatable workflows with your team to maximize productivity. Build one-click Agents to jump start Meeting Prep, generate IC Memos, or analyze Credit Agreements.\"},{\"sys\":{\"id\":\"3J9kK7CulyssOE1zIuRYZR\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3J9kK7CulyssOE1zIuRYZR/157706acbb5196cff9364213d5750833/company_investment_memo.gif\",\"description\":\"Build one-click Agents to jump start Meeting Prep, generate IC Memos, or analyze Credit Agreements.\"},{\"sys\":{\"id\":\"6FFmhwUJaxvOdOrMh8K1rD\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6FFmhwUJaxvOdOrMh8K1rD/b73f53bd128e85f365aa1879e6afcc8d/generate_columns_hebbia.gif\",\"description\":\"generate columns hebbia\"},{\"sys\":{\"id\":\"4IaGdVVTeFDfmBwN1PTZzP\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4IaGdVVTeFDfmBwN1PTZzP/99b777499e95e2eaf87f3eeb8d40da98/Product_Mock__5_.jpg\",\"description\":\"Every new doc you add to this Matrix is automatically analyzed for the same fields —financials, KPIs, covenants and headroom, maturity schedules, etc. —no prompting required. \\n\"},{\"sys\":{\"id\":\"7DVmwUnHJ63HPdg2015Hjr\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7DVmwUnHJ63HPdg2015Hjr/f2b0b0554c5d3d56df400f26e5e6dd2b/professional_pdf_exports.jpg\",\"description\":\"Generate memos, one-pagers, and research packs in minutes—ready to share with your team and MDs.\\n\"},{\"sys\":{\"id\":\"4rcARju8coftyjD3OwxpQR\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/4rcARju8coftyjD3OwxpQR/bb7142e47d15aafc938c40778dab196e/sector_insights.gif\",\"description\":\"We’ve added conference presentations to the Sector Insights library, alongside S\u0026P‑verified market news and conference transcripts.\"},{\"sys\":{\"id\":\"5lY8UAYIqitY7osYB81Fsr\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5lY8UAYIqitY7osYB81Fsr/123e238c40fb90297d44e83794b86fc5/web_crawler.gif\",\"description\":\"Ground your searches in vetted, up‑to‑date industry sources—skip the noise of unreliable web content.\\n\"},{\"sys\":{\"id\":\"1MP2Irsn33jJXUOFD3Oj7j\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/1MP2Irsn33jJXUOFD3Oj7j/fb6900db0d785125223cace12006c357/auto_extract_1.gif\",\"description\":\"Hebbia automatically detects and extracts all quantitative tables from every file for instant Excel export.\"},{\"sys\":{\"id\":\"56z8f0D7T11DTfbDdiqxuf\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/56z8f0D7T11DTfbDdiqxuf/bc7a033f2a81db1b9406bb7a317f9759/auto_extract_2.gif\",\"description\":\"Automatically pull financials from SEC filings, KPIs from investor decks, debt maturity schedules and cap tables from notes and press releases, precedent deal tables, and more. \\n\"}]}}}},{\"slug\":\"the-bottom-line-healthcare-earnings-q2-2025\",\"title\":\"The Bottom Line: Healthcare Earnings Reflect a Sector in Transition\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-08-14T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Sonal Gupta\",\"excerpt\":\"While the broader market is hitting record highs, the healthcare sector has lagged, down 5% following Q2 earnings.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/P53RhDtcx6EWoZXbg02EG/e6d66c0f9e795869f32fea6a10eb37ca/hebbia-tool-2025-08-13T20.08.48.140Z-1920x1920.jpg\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/P53RhDtcx6EWoZXbg02EG/e6d66c0f9e795869f32fea6a10eb37ca/hebbia-tool-2025-08-13T20.08.48.140Z-1920x1920.jpg\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/P53RhDtcx6EWoZXbg02EG/e6d66c0f9e795869f32fea6a10eb37ca/hebbia-tool-2025-08-13T20.08.48.140Z-1920x1920.jpg\"},\"content\":{\"json\":{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"While the broader market is hitting record highs—with the S\u0026P 500 up 7%—the healthcare sector has lagged, down 5% following Q2 earnings. To understand this underperformance, we used Hebbia’s Matrix to map the sector, identify key drivers, and conduct a detailed financial analysis.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Key takeaways\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Pharma revenue grew 6–8% YoY, but gross margins shrank 200–300bps, reflecting pricing pressures and competition between firms, resulting from anticipated One Big Beautiful Bill Act (OBBBA) cuts. Profitability now depends heavily on innovation and new drug launches.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Payers faced rising medical loss ratios, up roughly 180bps, squeezing margins and prompting UnitedHealth to cut EBITDA guidance by 4%. Claims inflation and regulatory caps limit the effectiveness of enrollment growth and premium increases.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Providers posted 5–7% volume growth, yet labor cost inflation of 6–8% trimmed operating margins by about 100bps. Volume alone no longer drives profit; cost control is essential.\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Device makers delivered 10–12% revenue growth and expanded margins by over 100bps, fueled by robotics and minimally invasive technologies. Innovation grants this segment pricing power and durable growth.\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Pharma: Innovation is essential as pricing power erodes\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Pharma companies like Pfizer and AbbVie are delivering revenue growth of 6–8%, but shrinking gross margins (down 200–300bps) reflect a fundamental shift. The OBBBA pricing reforms, especially on Medicare Part D (the part that covers pharmaceutical drugs), are eroding the pricing power that once fueled steady margin expansion. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"At the same time, competition between firms is driving prices lower in key categories. For instance, Eli Lilly's weight-loss medications Mounjaro and Zepbound captured 57% of the GLP-1 drug market in Q2 2025. While this marks strong uptake, intense competition with Novo Nordisk's Ozempic and Wegovy, combined with pricing pressures from OBBBA reforms, is compressing margins and weighing on profitability, contributing to the stock’s 14% decline. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Sustaining earnings growth hinges on successful R\u0026D, faster drug approvals, and commercializing new, high-value therapies. Without this pivot, rising costs and tighter pricing could compress profitability further, making innovation the sector’s lifeline.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Payers: Margin pressure intensifies amid rising costs\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Rising medical loss ratios, such as Cigna’s 83.2% in Q2 2025 (up from 82.3% in Q2 2024), reflect growing cost pressures that OBBBA’s Medicare cuts are exacerbating. Claims inflation from higher utilization, expensive new therapies, and regulatory caps on premium increases now interact with the policy-driven reimbursement reductions, further squeezing payers’ margins. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"UnitedHealth’s Medicare Advantage medical cost trend is projected at roughly 7.5% in 2025, above the pricing growth of just over 5%, with 2026 trends expected to accelerate toward 10%. Enrollment growth and premium rate hikes, once reliable levers, are no longer sufficient. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Maintaining profitability now requires aggressive care management, reduced avoidable claims, and operational efficiency—all under the new constraints imposed by OBBBA. The growing gap between premiums and medical costs is the defining margin challenge, reshaping how payers prioritize investments and manage growth.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Providers: Rising costs undermine volume gains\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Though providers are seeing volume growth, labor costs are going up. Workforce shortages and 6–8% wage inflation are compressing operating margins by roughly 100bps. For health systems like HCA and Tenet, more patients are coming through the door, but OBBBA-driven Medicare reimbursement cuts are reducing revenue per patient, intensifying the margin squeeze. Volume alone can no longer restore profitability. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Providers must innovate operationally, adopt technology to boost efficiency, and renegotiate payer contracts to offset rising costs and lower reimbursement rates. Without these changes, margin pressure will persist even as patient volumes recover.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Devices: Innovation drives earnings growth\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"In contrast, device manufacturers such as Medtronic and Stryker remain bright spots, posting 10–12% revenue growth and expanding margins by over 100bps. Demand for robotics and minimally invasive systems continues to drive adoption, and these technologies command premium pricing. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Unlike pharma or providers, device makers are largely insulated from OBBBA’s Medicare cuts, as their pricing is tied to clinical innovation rather than reimbursement rates. This innovation-led growth offers a stable earnings base, giving healthcare companies a buffer against the cost pressures and regulatory changes reshaping margins across the broader sector.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"heading-2\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Conclusion\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This earnings season underscores the reshaping healthcare’s profit landscape. This OBBBA introduced a significant cut to Medicaid spending and Medicare reimbursements, on top of existing restrictions on drug and insurance pricing. To set themselves apart, companies must accelerate R\u0026D, bring breakthrough therapies to market faster, or redesign care delivery for greater efficiency. \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Our use of Hebbia’s Matrix allowed us to quickly track policy shifts and earnings trends, providing a comprehensive view of the sector and helping us identify the key earnings drivers.\",\"marks\":[],\"data\":{}}]}]},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[]}}}},{\"slug\":\"the-next-edge-in-finance-reasoning-with-gpt-5-and-hebbia\",\"title\":\"The Next Edge in Finance: Reasoning with GPT‑5 \u0026 Hebbia\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-08-07T13:01:00.000-04:00\",\"category\":\"Product\",\"author\":\"George Sivulka\",\"excerpt\":\"As OpenAI’s research partner for financial services agents, we’ve spent weeks challenging GPT-5 on the most complex investing and banking workflows.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6ESmvsSkmHjiGy0VITxdM1/6a05058151afdb71f8cfdb387075eb29/91725_Blog_GPT5_CoverImage_1600x534.png\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3ObCEqal9SVp8C2sZ9HG70/b613cdabd37c921a5f22951a1c82c128/91725_Blog_GPT5_Thumbnail_1063x1080.png\"},\"blogHeader\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5Lg4Fj4JJD1LzrQRPrl6Bh/b71746c555ad74eb3e409e070078c8da/91725_Blog_GPT5_BlogHeader_1600x534.png\"},\"content\":{\"json\":{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"As OpenAI’s leading \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://openai.com/index/hebbia/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"research partner\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" for financial analysis, we’ve spent the last several weeks testing GPT-5 against the most complex financial agent workflows. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We’re excited to share our findings, and what the next generation of foundation models means for Wall Street and beyond.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Measuring AI-driven alpha\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The best investors spot patterns others miss. The best AI systems should be held to the same bar. Hebbia running on GPT-5 is the first system we’ve seen that truly unlocks alpha.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"To objectively measure a model’s originality, or its tendency towards novel idea generation, the Hebbia Applied Research team came up with the idea of “insightfulness” to evaluate LLMs on financial tasks. You can think of insightfulness as the ability to go beyond summarization to surface risks, opportunities, or strategic context that’s not explicitly stated. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Compared to every model we tested, GPT‑5 redefines state of the art.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"yrgDVDkLwATm5N6KFeZX3\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"italic\"},{\"type\":\"superscript\"}],\"value\":\"Financial Insightfulness measures whether the response goes beyond repeating existing information and surface implications, risks, opportunities, or strategic dynamics relevant to the prompt.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The first truly robust, truly agentic model\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"GPT-5’s capabilities extend far beyond novel pattern recognition. When put into Hebbia’s agentic finance environment, experiments revealed the most robust agent foundation we’ve ever seen:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Juggling dozens of tools: \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"Hebbia offers a rich financial agent sandbox, with connectors to S\u0026P Capital IQ, FactSet, Pitchbook, and dozens of datarooms and Sharepoint file trees. GPT-5 was the first model to truly tackle this complexity out of the box, elegantly selecting from a plethora of tools the exact APIs, integrations, and data sources to complete financial tasks end-to-end. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Agentic “fault tolerance”: \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"Rather than just following instructions, GPT‑5 is the first system we’ve seen that corrects its own work, \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"and even corrects your work. \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"It understands what you’re trying to do while exploring its environment, fills in missing info, and fixes errors, so your work keeps moving even when inputs aren’t perfect. It feels like it \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"undoes\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" hallucinations, even after going down a rabbit hole. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Analysis across multiple variables:\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" GPT‑5 cuts through noise to find the key drivers of a business–such as unit volumes, pricing, macro conditions—and uses them to build realistic financial projections. It builds upside, base, and downside scenarios where every assumption is traceable to real factors you can review and adjust.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"unordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"How we’ve used it \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We stress-tested GPT‑5 on four real-world workflows that matter most to finance teams.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Create three-statement financial models \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With Hebbia, GPT-5 pulled together the richest financial model we’ve seen, populating assumptions with accurate data pulls from key data sources like SEC filings, Virtual Data Rooms, S\u0026P Capital IQ, Pitchbook, FactSet, and PDFs. You can spend more time reviewing assumptions and refining the logic rather than spending hours on data entry. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Forecast financials with assumptions\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Unlike other models that focus only on high-level trends or single data points, GPT-5 can take into account multiple layers at once: company growth, industry-specific factors, market share shifts, pricing dynamics, macroeconomic conditions, and more. It uses all of these inputs to build full upside, downside, and base cases where the reasoning is transparent and you can adjust, challenge, and refine all of the assumptions and projections.  \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Correct errors by understanding intent\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We purposely threw GPT-5 a curveball: we asked it to build a model for a Norwegian company called “Autoshop”, which didn’t exist. After crawling CapIQ tables for public Norwegian companies, some of which were closer to the prompt, GPT-5 inferred that the intended company was “AutoStore,” and corrected the user. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Make polished presentations faster\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-3\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Storytelling still requires human judgment. With GPT‑5 in Hebbia, you can turn any analysis into reports and slide decks that follow your template. You can spend time refining the story with GPT-5 and polishing the slide outputs rather than starting from scratch.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"How you win with Hebbia\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Finance is entering an era where reasoning is automated but judgment remains human.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"GPT‑5 provides the reasoning, while Hebbia brings the data, integrations, agent environment, and workflows to use it.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The winners will be those who spend less time gathering information and more time thinking strategically—we’re excited to play a part in realizing this future.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[null]}}}},{\"blogHeader\":null,\"slug\":\"inside-hebbias-deeper-research-agent\",\"title\":\"Inside Hebbia’s “Deeper” Research Agent\",\"coverDisplay\":\"Full Width\",\"date\":\"2025-07-30T00:00:00.000-04:00\",\"category\":\"Product\",\"author\":\"Hebbia\",\"excerpt\":\"We created Deeper Research: a solution purpose-built for research-intensive industries like investing, banking, and law. It’s “deeper” because it introduces more steps in the research process and expands the range of data sources agents can search—including not just the web, but also private documents, PitchBook, S\u0026P CapIQ, and more.\",\"coverImage\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5C5awawXLbvnyAuMtgBhRQ/7520ad8cd5141d7d9a80df2dddde353e/deepester_research.jpg\"},\"thumbnail\":{\"url\":\"https://images.ctfassets.net/bn476u6z5acg/6Wbr4NQTLQuQVuOJ3DXam/a27179a0f22ab208438a662c56c4f438/hebbia-tool-2025-08-13T20.07.10.541Z-1920x1920.jpg\"},\"content\":{\"json\":{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Discovering novel answers requires connecting a wide range of seemingly unrelated ideas. This is a challenge our customers tackle every day. OpenAI’s \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://openai.com/index/introducing-deep-research/\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"launch\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" of Deep Research earlier this year transformed how people approach new domains, but as the technology spreads, it no longer gives our customers a competitive edge.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"That’s why we created \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Deeper Research\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": a solution purpose-built for research-intensive industries like investing, banking, and law. It’s “deeper” because it introduces more steps in the research process and expands the range of data sources agents can search—including not just the web, but also private documents, PitchBook, S\u0026P CapIQ, and more.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In this post, we’ll share how our research system works, how we’ve built around the limitations of MCP, and how we approach context engineering for high volumes of information. Ultimately, these innovations help make AI-powered research truly useful for the enterprise.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Power of Multi-Agent Systems \",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"While foundational LLMs offer impressive raw capabilities, it’s the collaboration of specialized agents that transforms these capabilities into enterprise-ready solutions. The future of intelligent systems for research tasks lies in architectures that can decompose complex goals, operate across diverse data sources, and dynamically adapt to new information. \",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Deeper Research\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" is powered by a team of dozens of \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.hebbia.com/blog/divide-and-conquer-hebbias-multi-agent-redesign\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"specialized\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\" agents. In any company, there’s usually a manager overseeing the work of several employees in different functions. The manager’s job is to make sure the employees are able to collaborate with each other to deliver results. Hebbia’s research agents operate the same way. Our system consists of the following agents:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Orchestrator\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Manage the research process, delegating tasks to each agent\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Planning\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Decompose complex research goals into actionable steps\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Retrieval\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Surface the most relevant data from public and private sources of data\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Document analysis\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Extract insights from unstructured documents\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Distillation\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Condense and structure information to fit within model context limits\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Reasoning\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Dynamically assess and refine the research process\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Output\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Synthesize findings and communicate with the user\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"unordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Our multi-agent team approaches research as an explore-exploit tradeoff. First, the team explores the breadth of the research surface area by decomposing a user’s request into broad, actionable subtasks and familiarizing itself with the latest available information. The system then exploits areas of interest based on what it has learned, iteratively adapting and refining its focus as new insights emerge.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"An agent can decompose an initial prompt into subtasks for other agents. Our framework is capable of spawning multiple subsystems of agents to tackle each subtask. This architecture gives our platform the flexibility to handle everything from straightforward questions to complex, multi-layered due diligence.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"3RBr40ISQwUoEUF0ZZqj3T\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In a research system that meticulously examines every detail in a vast amount of information, ensuring transparency is crucial to maintain trust and accountability. Our agents communicate every step and provide claims that link directly to the original document quotation. This is achieved through \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.hebbia.com/blog/goodbye-rag-how-hebbia-solved-information-retrieval-for-llms\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Iterative Source Decomposition (ISD)\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", which provides an audit trail to the precise source supporting the insight. Additionally, ISD can run on any LLM—OpenAI, Anthropic, Google—giving customers greater control over model selection to suit their specific needs.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"While agent collaboration is central to our system’s intelligence, the effectiveness of these agents depends on their ability to retrieve and process information from a wide variety of sources. The next section examines how we address the complexities of real-world data retrieval.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Beyond MCP: Information Retrieval for Real-World Complexity\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Our retrieval agents are designed to deliver higher accuracy, faster performance, and better coverage by tailoring their approach to the unique structure of each data source. They leverage bespoke data indexing, dynamic filtering, and multi-agent search strategies across the sources that matter most to our customers:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Private Data\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": User’s private data uploaded or synced from file stores (e.g., SharePoint, Box)\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Public Company Data\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": SEC filings, earnings call transcripts, and investor presentations\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"PitchBook\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Structured firmographic profiles for millions of companies\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"S\u0026P Capital IQ Financial\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Structured financial information from public and private companies\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Sector Insights\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": S\u0026P market news and conference transcripts\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Web\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Real-time access to information on the internet\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"unordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The Model Context Protocol (MCP) is an open standard that enables large language models (LLMs) to access data from a variety of sources, representing a significant step toward data interoperability. However, the effectiveness of an MCP server depends on how each partner or data provider configures it, and since MCP is relatively new, not every implementation supports all possible workflows. As a result, retrieving data tailored to specific use cases may require additional customization. For example, answering complex questions—such as “What were the ten most recent M\u0026A transactions in the chemicals sector over $10B?”—requires us to build custom indexing and search strategies to ensure reliable results. As the MCP ecosystem evolves, we remain committed to re-evaluating and adapting our approach to leverage future improvements.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"With robust retrieval strategies in place, the challenge shifts to managing the vast amount of information surfaced by our agents. This brings us to the critical topic of context engineering in high-volume research environments.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Managing Context in High-Volume Research\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"One of the key technical challenges in scaling inference across a network of agents is managing context. A single prompt can use millions of tokens to process thousands of pages and coordinate analysis from dozens of agents. Managing this scale requires sophisticated context engineering to control what each agent sees, shares, and retains.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We address context management with a multi-pronged approach:\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Roles and responsibilities\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Each agent has a clearly defined scope, ensuring only relevant history and information are included in its context.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Inter-agent communication\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Agents share only the information necessary for the next subtask, minimizing unnecessary context sharing.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"},{\"data\":{},\"content\":[{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Context distillation\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\": Information within the context window is compressed to its principal components, maximizing efficiency and relevance.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"list-item\"}],\"nodeType\":\"ordered-list\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"By defining precise roles and responsibilities, each agent operates within a well-bounded scope. For example, when an \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Orchestrator Agent\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\" needs to find revenue figures for two companies, it delegates each request to separate multi-agent subsystems. Each subsystem focuses on its specific assignment and operates independently. Agents return only their final results to the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Orchestrator Agent\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\", without sharing the details of how the information was found.\\n\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"7d6tpt5bZRzBQ3uvzEMyYm\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"In many cases, agents only need a summary of the results from other agents rather than verbatim outputs. To support this, we developed a specialized \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Context Distillation Agent\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\" \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"that reduces context to its principal components, allowing agents to leverage key insights and results. In our evaluation, the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Context Distillation Agent \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"reduces context size by over 90%, resulting in lower latency and higher recall. These targeted roles, selective communication, and context distillation techniques help reduce context size and enable agentic collaboration as the system scales to handle increasingly complex tasks.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"The greatest context engineering challenge lies with the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Output Agent\",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\". This agent is responsible for writing a fully cited, exhaustive report using every relevant quotation gathered from the research process. Since the \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[{\"type\":\"italic\"}],\"value\":\"Output Agent \",\"nodeType\":\"text\"},{\"data\":{},\"marks\":[],\"value\":\"can’t fit the entire body of research into its context window, it attends to relevant searches from the research. It writes the output section by section, using the output from previous sections as context for the current section. This “multi-hop” workflow enables our research process to generate comprehensive reports without ever exceeding its own context window.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{\"target\":{\"sys\":{\"id\":\"5WJuevd8kAlTum19NzICfM\",\"type\":\"Link\",\"linkType\":\"Asset\"}}},\"content\":[],\"nodeType\":\"embedded-asset-block\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"While scaling inference across multiple agents unlocks new levels of intelligence, we are still constrained by the rate limits of our LLM providers. To meet these demands, every request is routed through \",\"nodeType\":\"text\"},{\"data\":{\"uri\":\"https://www.hebbia.com/blog/maximizer-hebbias-distributed-system-for-high-scale-llm-request-scheduling\"},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Maximizer\",\"nodeType\":\"text\"}],\"nodeType\":\"hyperlink\"},{\"data\":{},\"marks\":[],\"value\":\", our high-throughput LLM orchestration system that dynamically allocates token capacity across providers. Maximizer prioritizes our most important tasks, adapts to real-time availability, and keeps inference flowing with a throughput of billions of tokens per day.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"What’s Next\",\"nodeType\":\"text\"}],\"nodeType\":\"heading-2\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Throughout this post, we’ve explored how Hebbia’s multi-agent system delivers accurate and actionable insights at an enterprise scale. By combining advanced context engineering, robust system orchestration, and a commitment to transparency and control, we aim to set a new standard for AI-powered research.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"We are grateful for the trust and feedback from our customers, which continually shapes our development. As the landscape of enterprise research evolves, we remain dedicated to advancing our technology and empowering our customers to tackle even more ambitious challenges.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Thank you for joining us on this journey. We look forward to sharing future innovations and invite you to stay engaged as we continue to push the boundaries of what’s possible with agentic AI systems.\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Author\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"William Luer\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Lead Technical Staff\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"William Luer, Bowen Zhang\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[{\"type\":\"bold\"}],\"value\":\"Engineering\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"Lucas Haarmann, Alex Flick, Jake Skinner, Sara Kemper, Tas Hasting, Adithya Ramanathan\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"},{\"data\":{},\"content\":[{\"data\":{},\"marks\":[],\"value\":\"+ with contributions from larger Hebbia technical staff\",\"nodeType\":\"text\"}],\"nodeType\":\"paragraph\"}],\"nodeType\":\"document\"},\"links\":{\"entries\":{\"block\":[]},\"assets\":{\"block\":[{\"sys\":{\"id\":\"3RBr40ISQwUoEUF0ZZqj3T\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/3RBr40ISQwUoEUF0ZZqj3T/a479e4bf7d5b64adc976f49dd4d94f22/Tariff_steps.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"7d6tpt5bZRzBQ3uvzEMyYm\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/7d6tpt5bZRzBQ3uvzEMyYm/9360e8d010ce39fbb5869a7545b2b6cc/Orchestration.jpg\",\"description\":\"\"},{\"sys\":{\"id\":\"5WJuevd8kAlTum19NzICfM\"},\"url\":\"https://images.ctfassets.net/bn476u6z5acg/5WJuevd8kAlTum19NzICfM/a9e9ee2fa2af7152ab486ef70b4c7abb/Hops.jpg\",\"description\":\"\"}]}}}}]}],[\"$\",\"$L19\",null,{}],[\"$\",\"$L1a\",null,{}]]}]\n"])</script></body></html>